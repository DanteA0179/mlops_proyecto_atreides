{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Optimization API - Ejemplos de Uso\n",
    "\n",
    "Este notebook demuestra cómo usar la API de predicción de consumo energético.\n",
    "\n",
    "**Prerrequisitos:**\n",
    "- API ejecutándose en `http://localhost:8000`\n",
    "- Modelo entrenado disponible en `models/ensembles/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Verificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "{\n",
      "  \"status\": \"healthy\",\n",
      "  \"service\": \"energy-optimization-api\",\n",
      "  \"version\": \"1.0.0\",\n",
      "  \"timestamp\": \"2025-11-06T20:41:52.005015Z\",\n",
      "  \"model_loaded\": true,\n",
      "  \"model_version\": \"stacking_ensemble_v1\",\n",
      "  \"uptime_seconds\": 569.81,\n",
      "  \"memory_usage_mb\": 362.92,\n",
      "  \"cpu_usage_percent\": 4.8\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# API base URL\n",
    "BASE_URL = \"http://localhost:8000\"\n",
    "\n",
    "# Verificar que la API está activa\n",
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "print(f\"Status: {response.status_code}\")\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: healthy\n",
      "Model Loaded: True\n",
      "Model Version: stacking_ensemble_v1\n",
      "Uptime: 600.24 seconds\n",
      "Memory: 362.92 MB\n",
      "CPU: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Verificar estado del servicio\n",
    "response = requests.get(f\"{BASE_URL}/health\")\n",
    "health = response.json()\n",
    "\n",
    "print(f\"Status: {health['status']}\")\n",
    "print(f\"Model Loaded: {health['model_loaded']}\")\n",
    "print(f\"Model Version: {health.get('model_version', 'N/A')}\")\n",
    "print(f\"Uptime: {health['uptime_seconds']:.2f} seconds\")\n",
    "print(f\"Memory: {health['memory_usage_mb']:.2f} MB\")\n",
    "print(f\"CPU: {health['cpu_usage_percent']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predicción Individual\n",
    "\n",
    "### 3.1 Ejemplo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predicción exitosa:\n",
      "  Consumo predicho: 44.46 kWh\n",
      "  ID: pred_17b22226\n",
      "  Modelo: stacking_ensemble_v1\n",
      "  Features usados: 9\n"
     ]
    }
   ],
   "source": [
    "# Preparar datos de entrada\n",
    "prediction_request = {\n",
    "    \"lagging_reactive_power\": 23.45,\n",
    "    \"leading_reactive_power\": 12.30,\n",
    "    \"co2\": 0.05,\n",
    "    \"lagging_power_factor\": 0.85,\n",
    "    \"leading_power_factor\": 0.92,\n",
    "    \"nsm\": 36000,  # 10:00 AM (36000 segundos desde medianoche)\n",
    "    \"day_of_week\": 1,  # Martes\n",
    "    \"load_type\": \"Medium\"\n",
    "}\n",
    "\n",
    "# Hacer predicción\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/predict\",\n",
    "    json=prediction_request\n",
    ")\n",
    "\n",
    "# Mostrar resultado\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\" OK Predicción exitosa:\")\n",
    "    print(f\"  Consumo predicho: {result['predicted_usage_kwh']:.2f} kWh\")\n",
    "    print(f\"  ID: {result['prediction_id']}\")\n",
    "    print(f\"  Modelo: {result['model_version']}\")\n",
    "    print(f\"  Features usados: {result['features_used']}\")\n",
    "else:\n",
    "    print(f\" X Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Predicción para diferentes horarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consumo por horario:\n",
      " hora  consumo_kwh\n",
      "00:00    41.141857\n",
      "06:00    45.045675\n",
      "12:00    44.456209\n",
      "18:00    44.456209\n"
     ]
    }
   ],
   "source": [
    "# Crear predicciones para diferentes horarios del día\n",
    "hours = [0, 6, 12, 18]  # Medianoche, 6 AM, 12 PM, 6 PM\n",
    "predictions = []\n",
    "\n",
    "for hour in hours:\n",
    "    nsm = hour * 3600  # Convertir hora a segundos desde medianoche\n",
    "    \n",
    "    request_data = {\n",
    "        \"lagging_reactive_power\": 23.45,\n",
    "        \"leading_reactive_power\": 12.30,\n",
    "        \"co2\": 0.05,\n",
    "        \"lagging_power_factor\": 0.85,\n",
    "        \"leading_power_factor\": 0.92,\n",
    "        \"nsm\": nsm,\n",
    "        \"day_of_week\": 1,\n",
    "        \"load_type\": \"Medium\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{BASE_URL}/predict\", json=request_data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        predictions.append({\n",
    "            \"hora\": f\"{hour:02d}:00\",\n",
    "            \"consumo_kwh\": result['predicted_usage_kwh']\n",
    "        })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_predictions = pd.DataFrame(predictions)\n",
    "print(\"\\nConsumo por horario:\")\n",
    "print(df_predictions.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Predicción para diferentes tipos de carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Consumo por tipo de carga:\n",
      "tipo_carga  consumo_kwh\n",
      "     Light    44.456209\n",
      "    Medium    44.456209\n",
      "   Maximum    44.456209\n"
     ]
    }
   ],
   "source": [
    "# Comparar consumo para diferentes tipos de carga\n",
    "load_types = [\"Light\", \"Medium\", \"Maximum\"]\n",
    "load_predictions = []\n",
    "\n",
    "for load_type in load_types:\n",
    "    request_data = {\n",
    "        \"lagging_reactive_power\": 23.45,\n",
    "        \"leading_reactive_power\": 12.30,\n",
    "        \"co2\": 0.05,\n",
    "        \"lagging_power_factor\": 0.85,\n",
    "        \"leading_power_factor\": 0.92,\n",
    "        \"nsm\": 36000,\n",
    "        \"day_of_week\": 1,\n",
    "        \"load_type\": load_type\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{BASE_URL}/predict\", json=request_data)\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        load_predictions.append({\n",
    "            \"tipo_carga\": load_type,\n",
    "            \"consumo_kwh\": result['predicted_usage_kwh']\n",
    "        })\n",
    "\n",
    "# Mostrar resultados\n",
    "df_load = pd.DataFrame(load_predictions)\n",
    "print(\"\\nConsumo por tipo de carga:\")\n",
    "print(df_load.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predicción Batch\n",
    "\n",
    "Predecir para múltiples observaciones a la vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Predicción batch exitosa\n",
      "\n",
      "Resumen:\n",
      "  Total predicciones: 3\n",
      "  Consumo promedio: 34.61 kWh\n",
      "  Consumo mínimo: 29.21 kWh\n",
      "  Consumo máximo: 44.46 kWh\n",
      "  Tiempo de procesamiento: 12.18 ms\n",
      "\n",
      "Predicciones individuales:\n",
      "  1. 44.46 kWh (ID: pred_cf5d1417)\n",
      "  2. 30.17 kWh (ID: pred_e8dc28eb)\n",
      "  3. 29.21 kWh (ID: pred_9485d50e)\n"
     ]
    }
   ],
   "source": [
    "# Crear batch de predicciones\n",
    "batch_request = {\n",
    "    \"predictions\": [\n",
    "        {\n",
    "            \"lagging_reactive_power\": 23.45,\n",
    "            \"leading_reactive_power\": 12.30,\n",
    "            \"co2\": 0.05,\n",
    "            \"lagging_power_factor\": 0.85,\n",
    "            \"leading_power_factor\": 0.92,\n",
    "            \"nsm\": 36000,\n",
    "            \"day_of_week\": 1,\n",
    "            \"load_type\": \"Medium\"\n",
    "        },\n",
    "        {\n",
    "            \"lagging_reactive_power\": 25.00,\n",
    "            \"leading_reactive_power\": 14.00,\n",
    "            \"co2\": 0.06,\n",
    "            \"lagging_power_factor\": 0.80,\n",
    "            \"leading_power_factor\": 0.90,\n",
    "            \"nsm\": 43200,\n",
    "            \"day_of_week\": 2,\n",
    "            \"load_type\": \"Light\"\n",
    "        },\n",
    "        {\n",
    "            \"lagging_reactive_power\": 30.00,\n",
    "            \"leading_reactive_power\": 16.00,\n",
    "            \"co2\": 0.08,\n",
    "            \"lagging_power_factor\": 0.88,\n",
    "            \"leading_power_factor\": 0.95,\n",
    "            \"nsm\": 57600,\n",
    "            \"day_of_week\": 3,\n",
    "            \"load_type\": \"Maximum\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Hacer predicción batch\n",
    "response = requests.post(\n",
    "    f\"{BASE_URL}/predict/batch\",\n",
    "    json=batch_request\n",
    ")\n",
    "\n",
    "# Mostrar resultados\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"OK Predicción batch exitosa\")\n",
    "    print(f\"\\nResumen:\")\n",
    "    print(f\"  Total predicciones: {result['summary']['total_predictions']}\")\n",
    "    print(f\"  Consumo promedio: {result['summary']['avg_predicted_usage']:.2f} kWh\")\n",
    "    print(f\"  Consumo mínimo: {result['summary']['min_predicted_usage']:.2f} kWh\")\n",
    "    print(f\"  Consumo máximo: {result['summary']['max_predicted_usage']:.2f} kWh\")\n",
    "    print(f\"  Tiempo de procesamiento: {result['summary']['processing_time_ms']:.2f} ms\")\n",
    "    \n",
    "    print(f\"\\nPredicciones individuales:\")\n",
    "    for i, pred in enumerate(result['predictions'], 1):\n",
    "        print(f\"  {i}. {pred['predicted_usage_kwh']:.2f} kWh (ID: {pred['prediction_id']})\")\n",
    "else:\n",
    "    print(f\"X Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Información del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Stacking Ensemble\n",
      "Versión: stacking_ensemble_v1\n",
      "Tipo: stacking_ensemble\n",
      "\n",
      "Dataset de entrenamiento:\n",
      "  Nombre: steel_featured.parquet\n",
      "  Samples: 27928\n",
      "  Features: 18\n",
      "\n",
      "Métricas de entrenamiento:\n",
      "  RMSE: 12.7982\n",
      "  R2: 0.8702\n",
      "  MAE: 3.4731\n",
      "  MAPE: 7.0100\n",
      "\n",
      "Modelos base del ensemble:\n",
      "  - XGBoost: 19.3%\n",
      "  - LightGBM: 40.5%\n",
      "  - CatBoost: 40.2%\n"
     ]
    }
   ],
   "source": [
    "# Obtener información del modelo\n",
    "response = requests.get(f\"{BASE_URL}/model/info\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    info = response.json()\n",
    "    print(f\"Modelo: {info['model_name']}\")\n",
    "    print(f\"Versión: {info['model_version']}\")\n",
    "    print(f\"Tipo: {info['model_type']}\")\n",
    "    \n",
    "    print(f\"\\nDataset de entrenamiento:\")\n",
    "    print(f\"  Nombre: {info['training_dataset']['name']}\")\n",
    "    print(f\"  Samples: {info['training_dataset']['samples']}\")\n",
    "    print(f\"  Features: {info['training_dataset']['features']}\")\n",
    "    \n",
    "    print(f\"\\nMétricas de entrenamiento:\")\n",
    "    for metric, value in info['training_metrics'].items():\n",
    "        print(f\"  {metric.upper()}: {value:.4f}\")\n",
    "    \n",
    "    if info.get('base_models'):\n",
    "        print(f\"\\nModelos base del ensemble:\")\n",
    "        for model in info['base_models']:\n",
    "            print(f\"  - {model['name']}: {model['contribution_pct']:.1f}%\")\n",
    "else:\n",
    "    print(f\"X Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Métricas del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de producción:\n",
      "  Total predicciones: 0\n",
      "  Últimas 24h: 0\n",
      "  Tiempo promedio: 0.00 ms\n",
      "  P95 tiempo: 0.00 ms\n",
      "  Tasa de error: 0.02%\n",
      "\n",
      "Salud del sistema:\n",
      "  Memoria: 256.50 MB\n",
      "  CPU: 15.20%\n",
      "  Uptime: 3600 segundos\n"
     ]
    }
   ],
   "source": [
    "# Obtener métricas actuales del modelo\n",
    "response = requests.get(f\"{BASE_URL}/model/metrics\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    metrics = response.json()\n",
    "    \n",
    "    print(\"Métricas de producción:\")\n",
    "    prod = metrics['production_metrics']\n",
    "    print(f\"  Total predicciones: {prod['total_predictions']}\")\n",
    "    print(f\"  Últimas 24h: {prod['predictions_last_24h']}\")\n",
    "    print(f\"  Tiempo promedio: {prod['avg_prediction_time_ms']:.2f} ms\")\n",
    "    print(f\"  P95 tiempo: {prod['p95_prediction_time_ms']:.2f} ms\")\n",
    "    print(f\"  Tasa de error: {prod['error_rate_percent']:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nSalud del sistema:\")\n",
    "    health = metrics['system_health']\n",
    "    print(f\"  Memoria: {health['memory_usage_mb']:.2f} MB\")\n",
    "    print(f\"  CPU: {health['cpu_usage_percent']:.2f}%\")\n",
    "    print(f\"  Uptime: {health['uptime_seconds']:.0f} segundos\")\n",
    "else:\n",
    "    print(f\"X Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Manejo de Errores\n",
    "\n",
    "### 7.1 Validación de rangos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 422\n",
      "Error: Validation Error\n",
      "  Campo: body -> lagging_power_factor\n",
      "  Mensaje: Input should be less than or equal to 1\n"
     ]
    }
   ],
   "source": [
    "# Intentar con power factor > 1.0 (inválido)\n",
    "invalid_request = {\n",
    "    \"lagging_reactive_power\": 23.45,\n",
    "    \"leading_reactive_power\": 12.30,\n",
    "    \"co2\": 0.05,\n",
    "    \"lagging_power_factor\": 1.5,  # INVÁLIDO: > 1.0\n",
    "    \"leading_power_factor\": 0.92,\n",
    "    \"nsm\": 36000,\n",
    "    \"day_of_week\": 1,\n",
    "    \"load_type\": \"Medium\"\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/predict\", json=invalid_request)\n",
    "print(f\"Status: {response.status_code}\")\n",
    "if response.status_code != 200:\n",
    "    error = response.json()\n",
    "    print(f\"Error: {error.get('error', error.get('detail'))}\")\n",
    "    if 'details' in error:\n",
    "        for detail in error['details']:\n",
    "            print(f\"  Campo: {detail['field']}\")\n",
    "            print(f\"  Mensaje: {detail['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Tipo de carga inválido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 422\n",
      "Error: Validation Error\n"
     ]
    }
   ],
   "source": [
    "# Intentar con load_type inválido\n",
    "invalid_request = {\n",
    "    \"lagging_reactive_power\": 23.45,\n",
    "    \"leading_reactive_power\": 12.30,\n",
    "    \"co2\": 0.05,\n",
    "    \"lagging_power_factor\": 0.85,\n",
    "    \"leading_power_factor\": 0.92,\n",
    "    \"nsm\": 36000,\n",
    "    \"day_of_week\": 1,\n",
    "    \"load_type\": \"Invalid\"  # INVÁLIDO: debe ser Light, Medium o Maximum\n",
    "}\n",
    "\n",
    "response = requests.post(f\"{BASE_URL}/predict\", json=invalid_request)\n",
    "print(f\"Status: {response.status_code}\")\n",
    "if response.status_code != 200:\n",
    "    error = response.json()\n",
    "    print(f\"Error: {error.get('error', error.get('detail'))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Uso con Python `requests`\n",
    "\n",
    "Ejemplo de función reutilizable para hacer predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK Consumo predicho: 44.46 kWh\n"
     ]
    }
   ],
   "source": [
    "def predict_energy_consumption(\n",
    "    lagging_reactive_power: float,\n",
    "    leading_reactive_power: float,\n",
    "    co2: float,\n",
    "    lagging_power_factor: float,\n",
    "    leading_power_factor: float,\n",
    "    nsm: int,\n",
    "    day_of_week: int,\n",
    "    load_type: str,\n",
    "    base_url: str = \"http://localhost:8000\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Make energy consumption prediction.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lagging_reactive_power : float\n",
    "        Potencia reactiva en atraso (kVarh)\n",
    "    leading_reactive_power : float\n",
    "        Potencia reactiva en adelanto (kVarh)\n",
    "    co2 : float\n",
    "        Emisiones de CO2 (tCO2)\n",
    "    lagging_power_factor : float\n",
    "        Factor de potencia en atraso (0-1)\n",
    "    leading_power_factor : float\n",
    "        Factor de potencia en adelanto (0-1)\n",
    "    nsm : int\n",
    "        Segundos desde medianoche (0-86400)\n",
    "    day_of_week : int\n",
    "        Día de la semana (0=Lunes, 6=Domingo)\n",
    "    load_type : str\n",
    "        Tipo de carga (Light, Medium, Maximum)\n",
    "    base_url : str\n",
    "        API base URL\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Prediction response\n",
    "    \n",
    "    Raises\n",
    "    ------\n",
    "    requests.HTTPError\n",
    "        If API request fails\n",
    "    \"\"\"\n",
    "    request_data = {\n",
    "        \"lagging_reactive_power\": lagging_reactive_power,\n",
    "        \"leading_reactive_power\": leading_reactive_power,\n",
    "        \"co2\": co2,\n",
    "        \"lagging_power_factor\": lagging_power_factor,\n",
    "        \"leading_power_factor\": leading_power_factor,\n",
    "        \"nsm\": nsm,\n",
    "        \"day_of_week\": day_of_week,\n",
    "        \"load_type\": load_type\n",
    "    }\n",
    "    \n",
    "    response = requests.post(f\"{base_url}/predict\", json=request_data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "# Usar la función\n",
    "try:\n",
    "    result = predict_energy_consumption(\n",
    "        lagging_reactive_power=23.45,\n",
    "        leading_reactive_power=12.30,\n",
    "        co2=0.05,\n",
    "        lagging_power_factor=0.85,\n",
    "        leading_power_factor=0.92,\n",
    "        nsm=36000,\n",
    "        day_of_week=1,\n",
    "        load_type=\"Medium\"\n",
    "    )\n",
    "    print(f\"OK Consumo predicho: {result['predicted_usage_kwh']:.2f} kWh\")\n",
    "except requests.HTTPError as e:\n",
    "    print(f\"X Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "Este notebook demostró:\n",
    "\n",
    "1. ✅ Verificación del estado de la API (`/health`)\n",
    "2. ✅ Predicciones individuales (`/predict`)\n",
    "3. ✅ Predicciones batch (`/predict/batch`)\n",
    "4. ✅ Información del modelo (`/model/info`)\n",
    "5. ✅ Métricas en tiempo real (`/model/metrics`)\n",
    "6. ✅ Manejo de errores y validaciones\n",
    "7. ✅ Funciones reutilizables en Python\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "energy-optimization-copilot-dSynOrhd-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
