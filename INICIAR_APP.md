# ğŸš€ GuÃ­a para Iniciar API + Streamlit

## ğŸ“‹ Requisitos Previos

1. **Poetry instalado** (para gestiÃ³n de dependencias)
2. **Python 3.11+**
3. **Modelo entrenado** (en `models/` o MLflow)

---

## ğŸ¯ OpciÃ³n 1: Inicio RÃ¡pido (Recomendado)

### Terminal 1: Iniciar API

```bash
# Desde la raÃ­z del proyecto
python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload
```

### Terminal 2: Iniciar Streamlit

```bash
# Desde la raÃ­z del proyecto
python -m streamlit run src/streamlit_app/app.py
```

### Acceder

- **Streamlit UI**: http://localhost:8501
- **API Docs**: http://localhost:8000/docs
- **API Health**: http://localhost:8000/health

---

## ğŸ”§ OpciÃ³n 2: Con Scripts

### Terminal 1: API

```bash
chmod +x scripts/start_api.sh
./scripts/start_api.sh
```

### Terminal 2: Streamlit

```bash
python -m streamlit run src/streamlit_app/app.py
```

---

## ğŸ³ OpciÃ³n 3: Con Docker Compose

```bash
# Construir e iniciar ambos servicios
docker-compose -f docker-compose.streamlit.yml up --build

# En segundo plano
docker-compose -f docker-compose.streamlit.yml up -d --build

# Ver logs
docker-compose -f docker-compose.streamlit.yml logs -f

# Detener
docker-compose -f docker-compose.streamlit.yml down
```

**Acceso:**
- Streamlit: http://localhost:8501
- API: http://localhost:8000

---

## ğŸ” Verificar que todo funciona

### 1. Verificar API

```bash
# Health check
curl http://localhost:8000/health

# Root endpoint
curl http://localhost:8000/
```

### 2. Verificar Streamlit

1. Abre http://localhost:8501
2. DeberÃ­as ver el mensaje "âœ… API Online" en el sidebar
3. Navega a "ğŸ”® PredicciÃ³n Simple"
4. Llena el formulario y haz una predicciÃ³n
5. Navega a "ğŸ¤– Copiloto Conversacional"
6. EnvÃ­a un mensaje

---

## âš ï¸ Troubleshooting

### Problema: API no inicia

**Error: "ModuleNotFoundError"**

```bash
# Instalar dependencias
poetry install

# O con pip
pip install -r requirements.txt
```

**Error: "Model not found"**

La API necesita un modelo entrenado. Opciones:

1. **Entrenar un modelo:**
```bash
python src/models/train_xgboost.py
```

2. **O usar modelo mock** (editar `src/api/utils/config.py`):
```python
MODEL_TYPE = "mock"  # En lugar de "xgboost"
```

### Problema: Streamlit no conecta con API

**SÃ­ntoma:** "âŒ API Offline" en el sidebar

**SoluciÃ³n:**

1. Verifica que la API estÃ© corriendo:
```bash
curl http://localhost:8000/health
```

2. Verifica la URL en Streamlit:
```python
# En src/streamlit_app/pages/__init__.py
API_BASE_URL = "http://localhost:8000"  # Debe ser correcta
```

3. Reinicia Streamlit:
```bash
# Ctrl+C para detener
# Luego reinicia
python -m streamlit run src/streamlit_app/app.py
```

### Problema: Puerto ya en uso

**Error: "Address already in use"**

**Para API (puerto 8000):**
```bash
# macOS/Linux
lsof -ti:8000 | xargs kill -9

# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

**Para Streamlit (puerto 8501):**
```bash
# macOS/Linux
lsof -ti:8501 | xargs kill -9

# Windows
netstat -ano | findstr :8501
taskkill /PID <PID> /F
```

### Problema: CORS errors

Si ves errores de CORS en el navegador, verifica que la API tiene CORS habilitado:

```python
# En src/api/main.py (ya deberÃ­a estar)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

---

## ğŸ“ Endpoints Disponibles

### API Endpoints

| Endpoint | MÃ©todo | DescripciÃ³n |
|----------|--------|-------------|
| `/` | GET | InformaciÃ³n de la API |
| `/health` | GET | Health check |
| `/predict` | POST | PredicciÃ³n simple |
| `/predict/batch` | POST | PredicciÃ³n por lotes |
| `/chat` | POST | Copiloto conversacional |
| `/model/info` | GET | InformaciÃ³n del modelo |
| `/model/metrics` | GET | MÃ©tricas del modelo |
| `/docs` | GET | DocumentaciÃ³n Swagger |

### Streamlit Pages

| PÃ¡gina | Ruta | DescripciÃ³n |
|--------|------|-------------|
| Home | `/` | PÃ¡gina de inicio |
| PredicciÃ³n Simple | `/` | Formulario de predicciÃ³n |
| Copiloto | `/` | Chat conversacional |

---

## ğŸ¨ Variables de Entorno (Opcional)

Crear archivo `.env` en la raÃ­z:

```bash
# API
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO

# MLflow (opcional)
MLFLOW_TRACKING_URI=http://localhost:5000

# Modelo
MODEL_TYPE=xgboost
MODEL_VERSION=latest

# Streamlit
API_URL=http://localhost:8000
```

---

## ğŸ”„ Flujo de Trabajo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   1. Iniciar API (Terminal 1)           â”‚
â”‚   python -m uvicorn src.api.main:app... â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   2. Verificar API                      â”‚
â”‚   curl http://localhost:8000/health     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   3. Iniciar Streamlit (Terminal 2)     â”‚
â”‚   streamlit run src/streamlit_app/app.pyâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   4. Acceder a http://localhost:8501    â”‚
â”‚   - Ver "âœ… API Online" en sidebar      â”‚
â”‚   - Probar predicciones                 â”‚
â”‚   - Probar chatbot                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Monitoreo

### Ver Logs de API

```bash
# Los logs se muestran en la terminal donde iniciaste la API
# O puedes redirigir a archivo:
python -m uvicorn src.api.main:app --host 0.0.0.0 --port 8000 --reload 2>&1 | tee api.log
```

### Ver Logs de Streamlit

```bash
# Los logs aparecen en la terminal de Streamlit
# TambiÃ©n se pueden ver en la UI (hamburger menu > Settings > Logs)
```

---

## ğŸ‰ Â¡Listo!

Si todo funciona correctamente, deberÃ­as ver:

- âœ… API corriendo en http://localhost:8000
- âœ… Streamlit corriendo en http://localhost:8501
- âœ… "âœ… API Online" en el sidebar de Streamlit
- âœ… Predicciones funcionando
- âœ… Chatbot respondiendo

---

## ğŸ“š DocumentaciÃ³n Adicional

- **API Docs**: http://localhost:8000/docs (Swagger UI interactivo)
- **API Redoc**: http://localhost:8000/redoc (DocumentaciÃ³n alternativa)
- **Streamlit Docs**: https://docs.streamlit.io/

---

## ğŸ†˜ Ayuda

Si tienes problemas:

1. Revisa los logs en ambas terminales
2. Verifica que todas las dependencias estÃ©n instaladas
3. AsegÃºrate de que los puertos 8000 y 8501 estÃ©n libres
4. Revisa este archivo para troubleshooting

**Â¡Disfruta tu aplicaciÃ³n de OptimizaciÃ³n EnergÃ©tica con IA!** ğŸš€âš¡
