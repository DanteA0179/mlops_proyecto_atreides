# ONNX Models - Energy Optimization Copilot

Este directorio contiene los modelos exportados a formato ONNX para inferencia optimizada.

## ğŸ“ Estructura

```
models/onnx/
â”œâ”€â”€ lightgbm.onnx              # Modelo LightGBM individual (476 KB)
â”œâ”€â”€ lightgbm.json              # Metadata del modelo
â””â”€â”€ lightgbm_ensemble/         # Ensemble completo (modelo principal)
    â”œâ”€â”€ lightgbm_base_lightgbm.onnx  # Base model LightGBM
    â”œâ”€â”€ lightgbm_base_catboost.onnx  # Base model CatBoost
    â”œâ”€â”€ lightgbm_meta.onnx           # Meta-model LightGBM
    â””â”€â”€ metadata.json                # Metadata del ensemble
```

## ğŸ¯ Modelo Principal

**ensemble_lightgbm_v3** (lightgbm_ensemble/)
- **RMSE**: 12.7982 (mejor modelo del proyecto)
- **Componentes**: 2 base models + 1 meta-model
- **TamaÃ±o total**: ~1.2 MB
- **Features esperadas**: 9 (post-preprocesamiento)

## ğŸš€ Uso

### Python con ONNX Runtime

```python
import onnxruntime as ort
import numpy as np

# Cargar modelo
session = ort.InferenceSession("models/onnx/lightgbm.onnx")

# Preparar datos (9 features)
features = np.random.randn(1, 9).astype(np.float32)

# Predecir
input_name = session.get_inputs()[0].name
prediction = session.run(None, {input_name: features})[0]

print(f"PredicciÃ³n: {prediction[0]:.2f} kWh")
```

### API REST

```bash
# PredicciÃ³n con ONNX (ensemble por defecto)
curl -X POST "http://localhost:8000/predict_onnx" \
  -H "Content-Type: application/json" \
  -d '{
    "lagging_reactive_power": 23.45,
    "leading_reactive_power": 12.30,
    "co2": 0.05,
    "lagging_power_factor": 0.85,
    "leading_power_factor": 0.92,
    "nsm": 36000,
    "day_of_week": 1,
    "load_type": "Medium"
  }'
```

## ğŸ“Š Performance

| MÃ©trica | Original | ONNX | Mejora |
|---------|----------|------|--------|
| TamaÃ±o | ~15 MB | ~1.2 MB | 92% â†“ |
| Dependencias | 500+ MB | 50 MB | 90% â†“ |
| Latencia (esperada) | ~15 ms | ~5 ms | 66% â†“ |

## âš™ï¸ ExportaciÃ³n

Para re-exportar los modelos:

```bash
# Exportar todos los modelos
poetry run python scripts/export_models_to_onnx.py

# Validar modelos exportados
poetry run python scripts/validate_onnx_models.py

# Benchmark de performance
poetry run python scripts/benchmark_onnx_models.py
```

## ğŸ”§ ConfiguraciÃ³n

Los archivos de configuraciÃ³n estÃ¡n en `config/onnx/`:
- `lightgbm_export.yaml` - Config para LightGBM
- `ensemble_export.yaml` - Config para ensemble
- `xgboost_export.yaml` - Config para XGBoost
- `catboost_export.yaml` - Config para CatBoost

## âš ï¸ Notas Importantes

1. **Features**: Los modelos esperan 9 features post-preprocesamiento, no 18
2. **XGBoost**: No exportado en el ensemble debido a incompatibilidad
3. **GPU**: Usar `CUDAExecutionProvider` para mejor performance
4. **ValidaciÃ³n**: Tolerancia numÃ©rica de 1e-4 (estÃ¡ndar para float32)

## ğŸ“š Referencias

- **US-021**: ExportaciÃ³n a ONNX
- **US-020**: API FastAPI
- **US-011**: Feature engineering temporal
- **US-012**: Preprocessing pipeline

---

**Ãšltima actualizaciÃ³n**: 15 de Noviembre, 2025
