# LightGBM Training Configuration
model:
  type: lightgbm
  version: v1.0

# Data paths (preprocessed from US-012)
data:
  train: data/processed/steel_preprocessed_train.parquet
  val: data/processed/steel_preprocessed_val.parquet
  test: data/processed/steel_preprocessed_test.parquet
  target_col: Usage_kWh

# Hyperparameters (baseline config)
hyperparameters:
  num_leaves: 31
  max_depth: 8
  learning_rate: 0.05
  n_estimators: 150
  subsample: 0.9
  colsample_bytree: 0.8
  reg_alpha: 5.0
  reg_lambda: 8.0
  min_child_samples: 20
  device: gpu  # Auto-fallback to cpu if no GPU
  random_state: 42
  verbose: -1

# Performance thresholds
thresholds:
  rmse: 15.0   # kWh
  r2: 0.80     # 80% variance explained
  mae: 4.0     # kWh

# MLflow configuration
mlflow:
  experiment_name: steel_energy_training_pipeline
  tracking_uri: http://localhost:5000
  tags:
    model_type: lightgbm
    pipeline_version: v1.0
    optimization: baseline

# DVC configuration
dvc:
  remote: gcs_remote
  auto_push: true
  skip_push: false

# Prefect configuration
prefect:
  flow_name: training-pipeline-lightgbm
  retries: 3
  timeout_seconds: 1800  # 30 minutes

# Notification configuration
notifications:
  channels:
    - console
    - file
  slack:
    enabled: false
    webhook_url: null
  email:
    enabled: false
    recipients: []
