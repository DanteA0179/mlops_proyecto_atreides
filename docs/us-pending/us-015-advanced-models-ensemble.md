# US-015: Advanced Models & Ensemble - Planning Document

**Estado**: ğŸ“‹ PENDIENTE  
**Prioridad**: ALTA  
**EstimaciÃ³n**: 5-6 dÃ­as  
**Responsables**: ML Engineer (Julian) + MLOps Engineer (Arthur)  
**Sprint**: 1 (Segunda Entrega)

---

## ğŸ“‹ Resumen Ejecutivo

Implementar tres modelos adicionales de gradient boosting (LightGBM, CatBoost) y un modelo de stacking ensemble que combine las predicciones de XGBoost, LightGBM y CatBoost para superar el benchmark CUBIST (RMSE normalizado < 0.205). Esta US busca maximizar el performance con mÃ­nimo esfuerzo reutilizando la infraestructura existente de US-013.

### Objetivo Principal

**Superar el benchmark CUBIST**: RMSE normalizado < 0.205 (actualmente en 0.3614 con XGBoost)

### Estrategia

1. **LightGBM** (DÃ­a 1-2): Competidor directo de XGBoost, alta probabilidad de mejora
2. **CatBoost** (DÃ­a 3-4): Manejo sofisticado de categÃ³ricas, puede capturar interacciones Ãºnicas
3. **Stacking Ensemble** (DÃ­a 5): Combinar los 3 modelos para maximizar performance
4. **AnÃ¡lisis Comparativo** (DÃ­a 6): SelecciÃ³n del mejor modelo y documentaciÃ³n

---

## ğŸ¯ Objetivos de Negocio

### Problema a Resolver


El modelo XGBoost baseline (US-013) logrÃ³ RMSE normalizado de 0.3614, lo cual estÃ¡ 76.4% por encima del target de 0.205. Necesitamos explorar modelos alternativos y tÃ©cnicas de ensemble para cerrar esta brecha.

### Valor Esperado

- **Mejora de Performance**: Reducir RMSE de 0.3614 a <0.205 (43% de mejora)
- **Robustez**: Ensemble reduce varianza y mejora generalizaciÃ³n
- **ComparaciÃ³n Justa**: Evaluar mÃºltiples algoritmos con misma metodologÃ­a
- **Aprendizaje**: Identificar quÃ© caracterÃ­sticas del dataset favorecen cada modelo

### MÃ©tricas de Ã‰xito

| MÃ©trica | Baseline (XGBoost) | Target | Stretch Goal |
|---------|-------------------|--------|--------------|
| RMSE normalizado | 0.3614 | < 0.205 | < 0.180 |
| RMSE (kWh) | 12.84 | < 7.28 | < 6.40 |
| RÂ² | 0.8693 | > 0.95 | > 0.96 |
| MAE (kWh) | 3.53 | < 2.50 | < 2.00 |

---

## ğŸ¯ Criterios de AceptaciÃ³n

### 1. Modelo LightGBM Entrenado y Optimizado

**Requisitos**:
- Pipeline sklearn con LGBMRegressor
- Reutilizar infraestructura de US-013 (xgboost_trainer.py como base)
- OptimizaciÃ³n de hiperparÃ¡metros con Optuna (100 trials mÃ­nimo)
- Cross-validation 5-fold
- GPU acceleration habilitado (device="gpu")

**HiperparÃ¡metros a optimizar**:
- `num_leaves`: (20, 150)
- `max_depth`: (-1, 15) # -1 = sin lÃ­mite
- `learning_rate`: (0.01, 0.3)
- `n_estimators`: (50, 300)
- `min_child_samples`: (5, 100)
- `subsample`: (0.6, 1.0)
- `colsample_bytree`: (0.6, 1.0)
- `reg_alpha`: (0, 10)
- `reg_lambda`: (0, 10)

**Entregables**:
- `src/models/lightgbm_trainer.py` (adaptado de xgboost_trainer.py)
- `src/models/train_lightgbm.py` (script ejecutable)
- Modelo serializado: `models/baselines/lightgbm_{version}.pkl`
- Metadata JSON con checksum
- Feature importance (gain, split)
- MLflow tracking completo

**MÃ©tricas esperadas**:
- RMSE: 10-12 kWh (mejora de 10-20% vs XGBoost)
- RÂ²: 0.88-0.90
- Training time: <5 min (100 trials)

---

### 2. Modelo CatBoost Entrenado y Optimizado

**Requisitos**:
- Pipeline sklearn con CatBoostRegressor
- Especificar features categÃ³ricas explÃ­citamente: `Load_Type`, `WeekStatus`
- OptimizaciÃ³n con Optuna (100 trials mÃ­nimo)
- Cross-validation 5-fold
- GPU acceleration habilitado (task_type="GPU")

**HiperparÃ¡metros a optimizar**:
- `depth`: (4, 10)
- `learning_rate`: (0.01, 0.3)
- `iterations`: (50, 300)
- `l2_leaf_reg`: (1, 10)
- `border_count`: (32, 255)
- `bagging_temperature`: (0, 1)
- `random_strength`: (0, 10)

**ConfiguraciÃ³n especial**:
```python
cat_features = ['Load_Type', 'WeekStatus']  # Ãndices o nombres
model = CatBoostRegressor(
    cat_features=cat_features,
    task_type="GPU",
    verbose=False
)
```

**Entregables**:
- `src/models/catboost_trainer.py`
- `src/models/train_catboost.py`
- Modelo serializado: `models/baselines/catboost_{version}.pkl`
- Metadata JSON
- Feature importance (PredictionValuesChange)
- MLflow tracking completo

**MÃ©tricas esperadas**:
- RMSE: 11-13 kWh
- RÂ²: 0.87-0.89
- Training time: <8 min (100 trials, CatBoost es mÃ¡s lento)

---

### 3. Stacking Ensemble Implementado

**Arquitectura**:

```
Level 0 (Base Models):
â”œâ”€â”€ XGBoost (ya entrenado en US-013)
â”œâ”€â”€ LightGBM (nuevo)
â””â”€â”€ CatBoost (nuevo)
         â†“
    Predicciones
         â†“
Level 1 (Meta-Model):
â””â”€â”€ Ridge Regression o LightGBM
         â†“
    PredicciÃ³n Final
```

**Requisitos**:
- Usar modelos ya optimizados (no re-entrenar)
- Generar predicciones out-of-fold para training del meta-modelo
- Probar 2 meta-modelos:
  1. Ridge Regression (simple, rÃ¡pido)
  2. LightGBM (puede capturar no-linealidades)
- Cross-validation para evaluar ensemble
- AnÃ¡lisis de pesos/importancia de cada modelo base

**Estrategia de implementaciÃ³n**:
1. Cargar modelos optimizados (XGBoost, LightGBM, CatBoost)
2. Generar predicciones out-of-fold en train set (5-fold CV)
3. Usar predicciones como features para meta-modelo
4. Entrenar meta-modelo en estas predicciones
5. Evaluar en test set

**Entregables**:
- `src/models/stacking_ensemble.py` (clase StackingEnsemble)
- `src/models/train_ensemble.py` (script ejecutable)
- Modelo serializado: `models/ensembles/stacking_{version}.pkl`
- AnÃ¡lisis de contribuciÃ³n de cada modelo base
- ComparaciÃ³n Ridge vs LightGBM como meta-modelo
- MLflow tracking completo

**MÃ©tricas esperadas**:
- RMSE: 9-11 kWh (mejora de 15-30% vs mejor modelo individual)
- RÂ²: 0.90-0.92
- ReducciÃ³n de varianza entre folds

---

### 4. ComparaciÃ³n Exhaustiva de Modelos

**AnÃ¡lisis requerido**:

**A. Tabla comparativa de mÃ©tricas**:
| Modelo | RMSE (kWh) | RMSE Norm | MAE (kWh) | RÂ² | MAPE (%) | Training Time |
|--------|------------|-----------|-----------|-----|----------|---------------|
| XGBoost | 12.84 | 0.3614 | 3.53 | 0.8693 | 31.46 | 4 min |
| LightGBM | TBD | TBD | TBD | TBD | TBD | TBD |
| CatBoost | TBD | TBD | TBD | TBD | TBD | TBD |
| Ensemble (Ridge) | TBD | TBD | TBD | TBD | TBD | TBD |
| Ensemble (LGBM) | TBD | TBD | TBD | TBD | TBD | TBD |
| **CUBIST (Target)** | **8.56** | **0.2410** | **-** | **-** | **-** | **-** |

**B. AnÃ¡lisis de errores por segmento**:
- Por `Load_Type` (Light, Medium, Maximum)
- Por `WeekStatus` (Weekday, Weekend)
- Por hora del dÃ­a (picos vs valles)
- Por rango de consumo (bajo, medio, alto)

**C. Feature importance comparison**:
- Top 10 features de cada modelo
- Consenso entre modelos
- Features Ãºnicas importantes por modelo

**D. AnÃ¡lisis de correlaciÃ³n de errores**:
- Â¿Los modelos cometen errores en los mismos puntos?
- CorrelaciÃ³n de residuos entre modelos
- Diversidad del ensemble (baja correlaciÃ³n = mejor ensemble)

**E. Visualizaciones**:
- Predictions vs Actual (todos los modelos en un plot)
- Residuals distribution (boxplot comparativo)
- Error por segmento (bar plots)
- Feature importance comparison (side-by-side)
- Scatter matrix de predicciones (correlaciÃ³n entre modelos)

**Entregables**:
- `notebooks/exploratory/11_model_comparison.ipynb`
- `reports/model_comparison_report.md`
- `reports/figures/model_comparison_*.png` (5-8 visualizaciones)
- RecomendaciÃ³n final de modelo para producciÃ³n

---

### 5. MLflow Tracking Completo

**Experimentos a crear**:
- `steel_energy_lightgbm_baseline`
- `steel_energy_catboost_baseline`
- `steel_energy_stacking_ensemble`

**MÃ©tricas a loggear** (para cada modelo):
- RMSE, MAE, RÂ², MAPE (train/val/test/cv)
- RMSE normalizado
- Max error, Min error
- Percentiles de error (p50, p75, p90, p95)
- Training time, Inference time
- Model size

**Artifacts a loggear**:
- Modelo serializado (solo path, no el archivo completo)
- Feature importance (JSON + PNG)
- Predictions vs Actual plot
- Residuals plot
- Optuna trials (CSV)
- Evaluation report (Markdown)

**Tags a asignar**:
- `model_type`: "lightgbm", "catboost", "ensemble"
- `experiment_type`: "baseline", "optimized", "ensemble"
- `model_version`: timestamp o manual
- `gpu_enabled`: "true"/"false"
- `optimization_method`: "optuna"
- `ensemble_type`: "stacking" (si aplica)
- `meta_model`: "ridge"/"lightgbm" (si aplica)

---

### 6. Sistema de Versionado y Reproducibilidad

**Requisitos**:
- Todos los modelos con versionado automÃ¡tico (timestamp)
- Metadata JSON para cada modelo:
  - Checksum MD5
  - HiperparÃ¡metros
  - MÃ©tricas de test
  - Fecha de entrenamiento
  - VersiÃ³n de librerÃ­as (lightgbm, catboost)
  - Random seed usado
- Reproducibilidad 100% con random_state=42
- Scripts ejecutables con argumentos CLI

**Estructura de directorios**:
```
models/
â”œâ”€â”€ baselines/
â”‚   â”œâ”€â”€ xgboost_v1.pkl (ya existe)
â”‚   â”œâ”€â”€ lightgbm_v1.pkl (nuevo)
â”‚   â”œâ”€â”€ lightgbm_v1.json
â”‚   â”œâ”€â”€ catboost_v1.pkl (nuevo)
â”‚   â””â”€â”€ catboost_v1.json
â””â”€â”€ ensembles/
    â”œâ”€â”€ stacking_ridge_v1.pkl (nuevo)
    â”œâ”€â”€ stacking_ridge_v1.json
    â”œâ”€â”€ stacking_lgbm_v1.pkl (nuevo)
    â””â”€â”€ stacking_lgbm_v1.json
```

---

## ğŸ› ï¸ ImplementaciÃ³n TÃ©cnica

### Fase 1: LightGBM (DÃ­as 1-2)

**Paso 1.1: Crear lightgbm_trainer.py**

**Base**: Copiar `src/models/xgboost_trainer.py` y adaptar

**Funciones a implementar**:
- `check_gpu_availability()` - Reutilizar de xgboost_trainer
- `create_lightgbm_pipeline()` - Similar a create_xgboost_pipeline
- `train_lightgbm_with_cv()` - Adaptar train_xgboost_with_cv
- `optimize_lightgbm_with_optuna()` - Adaptar optimize_xgboost_with_optuna
- `evaluate_model()` - Reutilizar de xgboost_trainer
- `get_feature_names_from_pipeline()` - Reutilizar

**Cambios clave**:
```python
# XGBoost â†’ LightGBM
from xgboost import XGBRegressor  # âŒ
from lightgbm import LGBMRegressor  # âœ…

DEFAULT_PARAMS = {
    "device": "gpu" if GPU_AVAILABLE else "cpu",
    "n_jobs": 1 if GPU_AVAILABLE else -1,
    "random_state": 42,
    "verbose": -1,
}

SEARCH_SPACE = {
    "num_leaves": (20, 150),
    "max_depth": (-1, 15),
    # ... resto de hiperparÃ¡metros
}
```

**Paso 1.2: Crear train_lightgbm.py**

**Base**: Copiar `src/models/train_xgboost.py` y adaptar

**Pipeline de 10 pasos** (igual que XGBoost):
1. Setup y configuraciÃ³n
2. GeneraciÃ³n de versiÃ³n del modelo
3. Carga de datos preprocesados (US-012)
4. OptimizaciÃ³n con Optuna (100 trials)
5. Cross-validation con mejores parÃ¡metros
6. EvaluaciÃ³n en train/val/test
7. ExtracciÃ³n de feature importance (gain + split)
8. GeneraciÃ³n de visualizaciones
9. Guardado de modelo y artifacts
10. Logging a MLflow

**Paso 1.3: Ejecutar y validar**

```bash
# Prueba rÃ¡pida (5 trials)
poetry run python src/models/train_lightgbm.py --n-trials 5 --cv-folds 3

# Entrenamiento completo
poetry run python src/models/train_lightgbm.py --n-trials 100 --cv-folds 5
```

**Validaciones**:
- âœ… GPU detection funciona
- âœ… Optuna converge
- âœ… Modelo se serializa correctamente
- âœ… MLflow registra todo
- âœ… Feature importance se genera

**Tiempo estimado**: 1.5-2 dÃ­as

---

### Fase 2: CatBoost (DÃ­as 3-4)

**Paso 2.1: Crear catboost_trainer.py**

**Base**: Copiar `lightgbm_trainer.py` y adaptar

**Diferencias clave con LightGBM**:
```python
from catboost import CatBoostRegressor, Pool

# CatBoost requiere especificar features categÃ³ricas
def create_catboost_pipeline(model_params, cat_features=None):
    # cat_features puede ser lista de Ã­ndices o nombres
    model = CatBoostRegressor(
        cat_features=cat_features,
        **model_params
    )
    # ... resto del pipeline

# Para Optuna, usar CatBoost Pool para eficiencia
def optimize_catboost_with_optuna(...):
    train_pool = Pool(
        X_train, 
        y_train,
        cat_features=cat_features
    )
    val_pool = Pool(X_val, y_val, cat_features=cat_features)
    # ... optimizaciÃ³n
```

**Identificar features categÃ³ricas**:
```python
# En el dataset preprocesado (US-012)
categorical_features = [
    'Load_Type_Light_Load',      # One-hot encoded
    'Load_Type_Medium_Load',     # One-hot encoded
    'Load_Type_Maximum_Load',    # One-hot encoded
    'WeekStatus',                # 0/1 (Weekday/Weekend)
]

# O usar columnas originales si no estÃ¡n one-hot encoded
# Verificar en data/processed/steel_train.parquet
```

**Paso 2.2: Crear train_catboost.py**

**Similar a train_lightgbm.py** con ajustes:
- Especificar `cat_features` en todos los pasos
- Usar `task_type="GPU"` en lugar de `device="gpu"`
- Feature importance: usar `PredictionValuesChange` (mÃ¡s informativo para CatBoost)

**Paso 2.3: Ejecutar y validar**

```bash
# Prueba rÃ¡pida
poetry run python src/models/train_catboost.py --n-trials 5 --cv-folds 3

# Entrenamiento completo
poetry run python src/models/train_catboost.py --n-trials 100 --cv-folds 5
```

**Tiempo estimado**: 1.5-2 dÃ­as

---

### Fase 3: Stacking Ensemble (DÃ­a 5)

**Paso 3.1: Crear stacking_ensemble.py**

**Clase principal**:
```python
class StackingEnsemble:
    """
    Stacking ensemble of multiple models.
    
    Level 0: Base models (XGBoost, LightGBM, CatBoost)
    Level 1: Meta-model (Ridge or LightGBM)
    """
    
    def __init__(self, base_models, meta_model, cv_folds=5):
        self.base_models = base_models
        self.meta_model = meta_model
        self.cv_folds = cv_folds
    
    def fit(self, X, y):
        # Generate out-of-fold predictions
        # Train meta-model on these predictions
    
    def predict(self, X):
        # Get predictions from base models
        # Feed to meta-model
```

**Funciones auxiliares**:
- `generate_oof_predictions()` - Out-of-fold predictions para training
- `train_meta_model()` - Entrenar meta-modelo
- `evaluate_ensemble()` - Evaluar ensemble completo
- `analyze_base_model_contributions()` - Pesos/importancia de cada modelo

**Paso 3.2: Crear train_ensemble.py**

**Pipeline**:
1. Cargar modelos optimizados:
   - `models/baselines/xgboost_v1.pkl`
   - `models/baselines/lightgbm_v1.pkl`
   - `models/baselines/catboost_v1.pkl`

2. Cargar datos preprocesados (US-012)

3. Generar predicciones out-of-fold (5-fold CV):
   - Para cada fold:
     - Train base models en 4 folds
     - Predict en 1 fold (out-of-fold)
   - Resultado: matriz (n_samples, 3) de predicciones

4. Entrenar meta-modelo Ridge:
   - Input: predicciones de los 3 modelos
   - Output: predicciÃ³n final
   - Analizar coeficientes (pesos de cada modelo)

5. Entrenar meta-modelo LightGBM:
   - Similar a Ridge
   - Puede capturar interacciones no-lineales

6. Evaluar ambos ensembles en test set

7. Comparar y seleccionar mejor

8. Guardar ensemble completo (base models + meta-model)

9. Logging a MLflow

**Paso 3.3: Ejecutar y validar**

```bash
poetry run python src/models/train_ensemble.py \
    --xgboost-model models/baselines/xgboost_v1.pkl \
    --lightgbm-model models/baselines/lightgbm_v1.pkl \
    --catboost-model models/baselines/catboost_v1.pkl \
    --meta-model ridge
```

**Tiempo estimado**: 1 dÃ­a

---

### Fase 4: AnÃ¡lisis Comparativo (DÃ­a 6)

**Paso 4.1: Crear notebook 11_model_comparison.ipynb**

**Secciones**:

1. **Setup y carga de modelos**
   - Cargar los 5 modelos (XGBoost, LightGBM, CatBoost, Ensemble Ridge, Ensemble LGBM)
   - Cargar datos de test

2. **ComparaciÃ³n de mÃ©tricas**
   - Tabla comparativa
   - Bar plots de RMSE, MAE, RÂ²
   - Identificar mejor modelo

3. **AnÃ¡lisis de errores por segmento**
   - Por Load_Type
   - Por WeekStatus
   - Por hora del dÃ­a
   - Por rango de consumo

4. **Feature importance comparison**
   - Top 10 de cada modelo
   - Heatmap de importancias
   - Consenso entre modelos

5. **AnÃ¡lisis de diversidad del ensemble**
   - CorrelaciÃ³n de predicciones entre modelos
   - Scatter matrix
   - CorrelaciÃ³n de residuos

6. **Visualizaciones comparativas**
   - Predictions vs Actual (todos los modelos)
   - Residuals distribution
   - Error distribution por modelo

7. **Conclusiones y recomendaciones**
   - Mejor modelo para producciÃ³n
   - Trade-offs (performance vs complejidad vs tiempo)
   - PrÃ³ximos pasos

**Paso 4.2: Crear model_comparison_report.md**

**Contenido**:
- Resumen ejecutivo
- Tabla de mÃ©tricas
- AnÃ¡lisis detallado de cada modelo
- Fortalezas y debilidades
- RecomendaciÃ³n final
- ApÃ©ndices con visualizaciones

**Paso 4.3: Generar visualizaciones**

**Figuras a crear** (guardar en `reports/figures/`):
1. `model_comparison_metrics.png` - Bar plot de mÃ©tricas
2. `model_comparison_predictions.png` - Predictions vs Actual
3. `model_comparison_residuals.png` - Boxplot de residuos
4. `model_comparison_by_load_type.png` - Error por Load_Type
5. `model_comparison_feature_importance.png` - Heatmap
6. `ensemble_diversity.png` - Scatter matrix de predicciones
7. `ensemble_weights.png` - ContribuciÃ³n de cada modelo base

**Tiempo estimado**: 1 dÃ­a

---

## ğŸ“Š Resultados Esperados

### Predicciones de Performance

**Escenario Conservador**:
| Modelo | RMSE (kWh) | RMSE Norm | RÂ² | Mejora vs XGBoost |
|--------|------------|-----------|-----|-------------------|
| XGBoost (baseline) | 12.84 | 0.3614 | 0.8693 | - |
| LightGBM | 12.20 | 0.3434 | 0.8750 | 5% |
| CatBoost | 12.50 | 0.3519 | 0.8720 | 2.6% |
| Ensemble (Ridge) | 11.80 | 0.3321 | 0.8800 | 8.1% |
| Ensemble (LGBM) | 11.60 | 0.3265 | 0.8830 | 9.7% |

**Escenario Optimista**:
| Modelo | RMSE (kWh) | RMSE Norm | RÂ² | Mejora vs XGBoost |
|--------|------------|-----------|-----|-------------------|
| XGBoost (baseline) | 12.84 | 0.3614 | 0.8693 | - |
| LightGBM | 11.50 | 0.3237 | 0.8850 | 10.4% |
| CatBoost | 11.80 | 0.3321 | 0.8800 | 8.1% |
| Ensemble (Ridge) | 10.80 | 0.3040 | 0.9000 | 15.9% |
| Ensemble (LGBM) | 10.50 | 0.2955 | 0.9050 | 18.2% |

**Target CUBIST**: RMSE Norm = 0.2410

**AnÃ¡lisis**:
- Escenario conservador: No alcanzamos target (0.3265 vs 0.2410)
- Escenario optimista: Nos acercamos pero no alcanzamos (0.2955 vs 0.2410)
- **ConclusiÃ³n**: Necesitaremos feature engineering adicional o modelos mÃ¡s avanzados

---

## ğŸš§ Riesgos y Mitigaciones

### Riesgo 1: No alcanzar el target CUBIST

**Probabilidad**: Alta (70%)  
**Impacto**: Alto

**MitigaciÃ³n**:
- Documentar claramente la metodologÃ­a usada
- Comparar con CUBIST en tÃ©rminos de features y preprocessing
- Si no alcanzamos, proponer US-016 con feature engineering avanzado
- Considerar que CUBIST puede usar metodologÃ­a diferente

### Riesgo 2: Overfitting del ensemble

**Probabilidad**: Media (40%)  
**Impacto**: Medio

**MitigaciÃ³n**:
- Usar out-of-fold predictions para training del meta-modelo
- Cross-validation riguroso
- RegularizaciÃ³n en meta-modelo (Ridge, L2 en LightGBM)
- Monitorear gap entre train y test metrics

### Riesgo 3: Modelos muy correlacionados (ensemble no mejora)

**Probabilidad**: Media (50%)  
**Impacto**: Medio

**MitigaciÃ³n**:
- Analizar correlaciÃ³n de predicciones antes de crear ensemble
- Si correlaciÃ³n > 0.95, considerar solo el mejor modelo individual
- Diversificar hiperparÃ¡metros en optimizaciÃ³n
- Considerar agregar modelo de familia diferente (ej. Random Forest)

### Riesgo 4: Tiempo de entrenamiento excesivo

**Probabilidad**: Baja (20%)  
**Impacto**: Bajo

**MitigaciÃ³n**:
- GPU acceleration en todos los modelos
- Reducir trials de Optuna si es necesario (50 en lugar de 100)
- Paralelizar entrenamientos (LightGBM y CatBoost en paralelo)
- Usar early stopping en Optuna

### Riesgo 5: Problemas con GPU en CatBoost

**Probabilidad**: Media (30%)  
**Impacto**: Bajo

**MitigaciÃ³n**:
- Fallback automÃ¡tico a CPU si GPU falla
- Documentar configuraciÃ³n de GPU para CatBoost
- Probar en CPU primero si hay problemas

---

## ğŸ“ Estructura de Archivos

### CÃ³digo Fuente (Nuevo)

```
src/models/
â”œâ”€â”€ lightgbm_trainer.py          # ~500 lÃ­neas (adaptado de xgboost_trainer.py)
â”œâ”€â”€ train_lightgbm.py            # ~380 lÃ­neas (adaptado de train_xgboost.py)
â”œâ”€â”€ catboost_trainer.py          # ~520 lÃ­neas (similar a lightgbm_trainer.py)
â”œâ”€â”€ train_catboost.py            # ~400 lÃ­neas (similar a train_lightgbm.py)
â”œâ”€â”€ stacking_ensemble.py         # ~350 lÃ­neas (nuevo)
â””â”€â”€ train_ensemble.py            # ~300 lÃ­neas (nuevo)
```

### Modelos Generados

```
models/
â”œâ”€â”€ baselines/
â”‚   â”œâ”€â”€ lightgbm_v1.pkl          # ~2-3 MB
â”‚   â”œâ”€â”€ lightgbm_v1.json
â”‚   â”œâ”€â”€ catboost_v1.pkl          # ~5-8 MB (CatBoost es mÃ¡s grande)
â”‚   â””â”€â”€ catboost_v1.json
â””â”€â”€ ensembles/
    â”œâ”€â”€ stacking_ridge_v1.pkl    # ~15 MB (incluye 3 base models)
    â”œâ”€â”€ stacking_ridge_v1.json
    â”œâ”€â”€ stacking_lgbm_v1.pkl     # ~15 MB
    â””â”€â”€ stacking_lgbm_v1.json
```

### Reportes y Visualizaciones

```
reports/
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ lightgbm_test_metrics_v1.json
â”‚   â”œâ”€â”€ catboost_test_metrics_v1.json
â”‚   â”œâ”€â”€ ensemble_ridge_test_metrics_v1.json
â”‚   â”œâ”€â”€ ensemble_lgbm_test_metrics_v1.json
â”‚   â”œâ”€â”€ optuna_trials_lightgbm_v1.csv
â”‚   â””â”€â”€ optuna_trials_catboost_v1.csv
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ lightgbm_predictions_v1.png
â”‚   â”œâ”€â”€ lightgbm_residuals_v1.png
â”‚   â”œâ”€â”€ lightgbm_feature_importance_v1.png
â”‚   â”œâ”€â”€ catboost_predictions_v1.png
â”‚   â”œâ”€â”€ catboost_residuals_v1.png
â”‚   â”œâ”€â”€ catboost_feature_importance_v1.png
â”‚   â”œâ”€â”€ ensemble_predictions_v1.png
â”‚   â”œâ”€â”€ model_comparison_metrics.png
â”‚   â”œâ”€â”€ model_comparison_predictions.png
â”‚   â”œâ”€â”€ model_comparison_residuals.png
â”‚   â”œâ”€â”€ model_comparison_by_load_type.png
â”‚   â”œâ”€â”€ model_comparison_feature_importance.png
â”‚   â”œâ”€â”€ ensemble_diversity.png
â”‚   â””â”€â”€ ensemble_weights.png
â””â”€â”€ model_comparison_report.md   # ~1000 lÃ­neas
```

### Notebooks

```
notebooks/exploratory/
â””â”€â”€ 11_model_comparison.ipynb    # AnÃ¡lisis comparativo completo
```

---

## ğŸ’» Comandos de EjecuciÃ³n

### Entrenamiento Individual

```bash
# LightGBM
poetry run python src/models/train_lightgbm.py --n-trials 100 --cv-folds 5

# CatBoost
poetry run python src/models/train_catboost.py --n-trials 100 --cv-folds 5

# Con versiÃ³n manual
poetry run python src/models/train_lightgbm.py \
    --n-trials 100 \
    --cv-folds 5 \
    --model-version production_v1
```

### Ensemble

```bash
# Stacking con Ridge
poetry run python src/models/train_ensemble.py \
    --xgboost-model models/baselines/xgboost_v1.pkl \
    --lightgbm-model models/baselines/lightgbm_v1.pkl \
    --catboost-model models/baselines/catboost_v1.pkl \
    --meta-model ridge \
    --cv-folds 5

# Stacking con LightGBM
poetry run python src/models/train_ensemble.py \
    --xgboost-model models/baselines/xgboost_v1.pkl \
    --lightgbm-model models/baselines/lightgbm_v1.pkl \
    --catboost-model models/baselines/catboost_v1.pkl \
    --meta-model lightgbm \
    --cv-folds 5
```

### Pruebas RÃ¡pidas

```bash
# LightGBM rÃ¡pido (5 trials, 3 folds)
poetry run python src/models/train_lightgbm.py --n-trials 5 --cv-folds 3

# CatBoost rÃ¡pido
poetry run python src/models/train_catboost.py --n-trials 5 --cv-folds 3
```

---

## ğŸ§ª Testing y ValidaciÃ³n

### Tests Unitarios a Crear

```
tests/unit/
â”œâ”€â”€ test_lightgbm_trainer.py     # ~15 tests
â”œâ”€â”€ test_catboost_trainer.py     # ~15 tests
â””â”€â”€ test_stacking_ensemble.py    # ~20 tests
```

**Tests clave**:
- GPU detection funciona
- Pipeline se crea correctamente
- Modelos se serializan/deserializan
- Feature importance se extrae
- Ensemble genera predicciones correctas
- Out-of-fold predictions son vÃ¡lidas
- Meta-modelo se entrena correctamente

### ValidaciÃ³n Manual

**Checklist**:
- [ ] LightGBM entrena sin errores
- [ ] CatBoost maneja categÃ³ricas correctamente
- [ ] GPU se usa en ambos modelos
- [ ] Optuna converge en <100 trials
- [ ] Modelos se guardan con versionado
- [ ] MLflow registra todo correctamente
- [ ] Ensemble mejora vs modelos individuales
- [ ] Predicciones son razonables (no NaN, no negativos)
- [ ] Reproducibilidad con random_state=42

---

## ğŸ“š Dependencias

### Nuevas LibrerÃ­as

```toml
# pyproject.toml
[tool.poetry.dependencies]
lightgbm = "^4.1.0"      # Ya debe estar instalado
catboost = "^1.2.2"      # NUEVO - agregar
```

**InstalaciÃ³n**:
```bash
poetry add catboost
```

**Verificar versiones**:
```bash
poetry show lightgbm catboost
```

---

## ğŸ“ Lecciones Esperadas

### Aprendizajes TÃ©cnicos

1. **ComparaciÃ³n de algoritmos de gradient boosting**
   - Diferencias entre XGBoost, LightGBM, CatBoost
   - CuÃ¡ndo usar cada uno

2. **Manejo de features categÃ³ricas**
   - One-hot encoding vs categorical encoding nativo
   - Ventajas de CatBoost

3. **Stacking ensemble**
   - CÃ³mo generar out-of-fold predictions
   - SelecciÃ³n de meta-modelo
   - Trade-off complejidad vs mejora

4. **OptimizaciÃ³n de hiperparÃ¡metros**
   - Search spaces especÃ­ficos por algoritmo
   - Convergencia de Optuna

### Aprendizajes de Negocio

1. **Benchmarking**
   - Importancia de metodologÃ­a consistente
   - ComparaciÃ³n justa entre modelos

2. **Trade-offs**
   - Performance vs complejidad
   - Performance vs tiempo de entrenamiento
   - Performance vs interpretabilidad

---

## ğŸ”„ PrÃ³ximos Pasos (Post US-015)

### Si alcanzamos el target (RMSE < 0.205)

**US-016: Model Deployment & API**
- Optimizar modelo para inference
- Crear endpoint FastAPI
- Testing de latencia
- Deployment a Cloud Run

### Si NO alcanzamos el target

**US-016: Advanced Feature Engineering**
- Lag features (1h, 2h, 4h, 8h, 24h)
- Rolling statistics (mean, std, min, max)
- Interacciones entre features
- Polynomial features
- Target encoding para categÃ³ricas
- Time-based features (dÃ­a del mes, semana del aÃ±o)

**US-017: Deep Learning Models**
- Temporal Fusion Transformer (TFT)
- N-BEATS
- LSTM/GRU
- Comparar con gradient boosting

---

## ğŸ“Š MÃ©tricas de Calidad del CÃ³digo

### Targets

| MÃ©trica | Target | CÃ³mo Medir |
|---------|--------|------------|
| LÃ­neas de cÃ³digo | ~2,500 | `cloc src/models/` |
| Funciones | >20 | Contar funciones |
| Docstrings | 100% | RevisiÃ³n manual |
| Type hints | 100% | RevisiÃ³n manual |
| Tests coverage | >70% | `pytest --cov` |
| Ruff warnings | <5 | `ruff check .` |
| Black compliant | SÃ­ | `black --check .` |

### Performance Targets

| MÃ©trica | Target |
|---------|--------|
| LightGBM training (100 trials) | <5 min |
| CatBoost training (100 trials) | <8 min |
| Ensemble training | <2 min |
| Total time (todo el pipeline) | <20 min |

---

## âœ… Definition of Done

### CÃ³digo
- [ ] `lightgbm_trainer.py` implementado y testeado
- [ ] `train_lightgbm.py` ejecutable con CLI args
- [ ] `catboost_trainer.py` implementado y testeado
- [ ] `train_catboost.py` ejecutable con CLI args
- [ ] `stacking_ensemble.py` implementado y testeado
- [ ] `train_ensemble.py` ejecutable con CLI args
- [ ] Todos los mÃ³dulos con docstrings y type hints
- [ ] CÃ³digo formateado con Black
- [ ] Sin warnings de Ruff (o <5 menores)

### Modelos
- [ ] LightGBM entrenado y optimizado (100 trials)
- [ ] CatBoost entrenado y optimizado (100 trials)
- [ ] Ensemble Ridge entrenado
- [ ] Ensemble LightGBM entrenado
- [ ] Todos los modelos serializados con versionado
- [ ] Metadata JSON generado para cada modelo

### MLflow
- [ ] 3 experimentos creados (lightgbm, catboost, ensemble)
- [ ] Todos los parÃ¡metros loggeados
- [ ] Todas las mÃ©tricas loggeadas
- [ ] Artifacts subidos (plots, CSVs, reports)
- [ ] Tags asignados correctamente

### AnÃ¡lisis
- [ ] Notebook `11_model_comparison.ipynb` completo
- [ ] `model_comparison_report.md` generado
- [ ] 7 visualizaciones creadas
- [ ] Tabla comparativa de mÃ©tricas
- [ ] AnÃ¡lisis de errores por segmento
- [ ] Feature importance comparison
- [ ] RecomendaciÃ³n final documentada

### DocumentaciÃ³n
- [ ] `us-015.md` completion doc creado
- [ ] README actualizado con nuevos modelos
- [ ] Ejemplos de uso documentados
- [ ] Lecciones aprendidas documentadas

### Testing
- [ ] Tests unitarios para nuevos mÃ³dulos (>70% coverage)
- [ ] ValidaciÃ³n manual completada
- [ ] Reproducibilidad verificada

### Calidad
- [ ] CÃ³digo revisado por peer
- [ ] Performance targets alcanzados
- [ ] Sin errores en ejecuciÃ³n
- [ ] DocumentaciÃ³n clara y completa

---

## ğŸ¯ Criterios de Ã‰xito Final

### MÃ­nimo Viable (Must Have)

âœ… **3 modelos entrenados**: XGBoost (ya existe), LightGBM, CatBoost  
âœ… **1 ensemble funcional**: Stacking con Ridge o LightGBM  
âœ… **Mejora vs baseline**: Al menos 5% de mejora en RMSE  
âœ… **MLflow tracking**: Completo para todos los modelos  
âœ… **AnÃ¡lisis comparativo**: Notebook y reporte completos  
âœ… **DocumentaciÃ³n**: US completion doc detallado  

### Deseable (Should Have)

âœ… **2 ensembles**: Ridge y LightGBM comparados  
âœ… **Mejora vs baseline**: 10-15% de mejora en RMSE  
âœ… **AnÃ¡lisis profundo**: Errores por segmento, feature importance  
âœ… **Tests unitarios**: >70% coverage  
âœ… **Visualizaciones**: 7+ figuras de alta calidad  

### Aspiracional (Nice to Have)

âœ… **Alcanzar target CUBIST**: RMSE normalizado < 0.205  
âœ… **Mejora vs baseline**: >20% de mejora en RMSE  
âœ… **Modelo production-ready**: Seleccionado y optimizado  
âœ… **Insights accionables**: Recomendaciones para feature engineering  

---

## ğŸ“ Puntos de Contacto

### Revisiones Intermedias

**DÃ­a 2**: RevisiÃ³n de LightGBM
- Â¿Entrena correctamente?
- Â¿Mejora vs XGBoost?
- Â¿GPU funciona?

**DÃ­a 4**: RevisiÃ³n de CatBoost
- Â¿Maneja categÃ³ricas correctamente?
- Â¿Performance comparable?
- Â¿Listo para ensemble?

**DÃ­a 5**: RevisiÃ³n de Ensemble
- Â¿Mejora vs modelos individuales?
- Â¿QuÃ© meta-modelo es mejor?
- Â¿Listo para anÃ¡lisis final?

### Decisiones Clave

**DecisiÃ³n 1** (DÃ­a 2): Â¿Continuar con CatBoost?
- Si LightGBM no mejora significativamente, reevaluar
- Considerar invertir tiempo en feature engineering

**DecisiÃ³n 2** (DÃ­a 5): Â¿QuÃ© meta-modelo usar?
- Ridge (simple) vs LightGBM (complejo)
- Basado en performance y complejidad

**DecisiÃ³n 3** (DÃ­a 6): Â¿Modelo final para producciÃ³n?
- Basado en mÃ©tricas, complejidad, interpretabilidad
- Documentar decisiÃ³n y trade-offs

---

## ğŸ† Impacto Esperado

### TÃ©cnico

- **3 nuevos modelos baseline** de alta calidad
- **Sistema de ensemble** reutilizable
- **Framework de comparaciÃ³n** de modelos
- **Mejora de 10-20%** en RMSE vs XGBoost

### AcadÃ©mico

- **ComparaciÃ³n rigurosa** de algoritmos de gradient boosting
- **AnÃ¡lisis de ensemble methods** en series temporales
- **Insights sobre el dataset** (quÃ© features importan, quÃ© modelos funcionan mejor)
- **DocumentaciÃ³n de alta calidad** para el proyecto

### Proyecto

- **Acercamiento al target** CUBIST (aunque probablemente no lo alcancemos)
- **Base sÃ³lida** para feature engineering adicional
- **Modelo candidato** para deployment
- **Aprendizajes** para Sprint 2

---

**EstimaciÃ³n Total**: 5-6 dÃ­as  
**Prioridad**: ALTA  
**Dependencias**: US-012 (Preprocessing), US-013 (XGBoost)  
**Bloqueantes**: Ninguno  

---

*Documento de planeaciÃ³n creado por MLOps Team - Proyecto Atreides*  
*Fecha: 2025-10-30*  
*VersiÃ³n: 1.0*
