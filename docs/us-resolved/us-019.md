# US-019: Migraci√≥n a Dagster y Soporte Multi-Modelo

**Estado**: ‚úÖ Resuelto  
**Fecha**: Noviembre 2025  
**Tipo**: MLOps Infrastructure + Multi-Model Support

---

## üìã Resumen Ejecutivo

Se migr√≥ exitosamente el sistema de orquestaci√≥n de pipelines de ML desde **Prefect v3** a **Dagster 1.9.0**, implementando soporte completo para 8 modelos de machine learning con cambio de modelo mediante solo edici√≥n de archivos YAML.

**Problema Original**: Prefect v3 presentaba problemas cr√≠ticos en la UI (requer√≠a workers, errores de websockets) que imped√≠an la visualizaci√≥n y monitoreo de flujos.

**Soluci√≥n Implementada**: Dagster con arquitectura multi-modelo, detecci√≥n autom√°tica de GPU, integraci√≥n con MLflow/DVC, y soporte para foundation models (Chronos-2).

---

## üéØ Objetivos Cumplidos

### ‚úÖ Objetivo 1: Migraci√≥n Prefect ‚Üí Dagster
- Migraci√≥n completa de arquitectura
- UI funcional sin workers en http://localhost:3000
- 0 regresiones en funcionalidad existente

### ‚úÖ Objetivo 2: Soporte Multi-Modelo
- 8 modelos soportados:
  - XGBoost (tradicional ML)
  - LightGBM (tradicional ML)
  - CatBoost (tradicional ML)
  - Stacking Ensemble
  - Voting Ensemble
  - Chronos-2 Zero-shot (foundation model)
  - Chronos-2 Fine-tuned (foundation model)
  - Chronos-2 Covariates (foundation model)
- Cambio de modelo SIN tocar c√≥digo (solo YAML)

### ‚úÖ Objetivo 3: Foundation Model Integration
- Pipeline completo para Chronos-2 (amazon/chronos-t5-small)
- 3 configuraciones YAML para diferentes enfoques
- GPU autom√°tico con fallback a CPU
- Fine-tuning con/sin covariables

### ‚úÖ Objetivo 4: Developer Experience
- Scripts de inicio (`start-dagster.ps1`, `start-dagster.sh`)
- Documentaci√≥n consolidada en gu√≠a √∫nica
- Configuraci√≥n autom√°tica de DAGSTER_HOME
- **Configuraci√≥n prellenada en Launchpad** - valores por defecto listos para usar

---

## üèóÔ∏è Arquitectura

### Estructura de C√≥digo

```
src/dagster_pipeline/
‚îú‚îÄ‚îÄ definitions.py          # Entry point - 4 jobs registrados
‚îú‚îÄ‚îÄ ops.py                  # 10 ops para modelos tradicionales
‚îú‚îÄ‚îÄ chronos_ops.py          # 7 ops para Chronos-2
‚îú‚îÄ‚îÄ jobs.py                 # Job de modelos tradicionales
‚îú‚îÄ‚îÄ chronos_jobs.py         # 3 jobs de Chronos-2
‚îî‚îÄ‚îÄ working_pipeline.py     # Pipeline principal multi-modelo
```

### Jobs Implementados

| Job | Modelos | Ops | Prop√≥sito |
|-----|---------|-----|-----------|
| `complete_training_job` | XGBoost, LightGBM, CatBoost, 2 Ensembles | 10 | Entrenamiento tradicional ML |
| `chronos_zeroshot_job` | Chronos-2 (pre-trained) | 6 | Inference sin entrenamiento |
| `chronos_finetuned_job` | Chronos-2 (fine-tuned) | 8 | Fine-tuning simple |
| `chronos_covariates_job` | Chronos-2 (9 covariables) | 8 | Fine-tuning multivariado |

### Ops de Chronos-2

```python
# src/dagster_pipeline/chronos_ops.py
load_chronos_config_op()       # Carga YAML config (con valores por defecto)
load_chronos_data_op()         # Carga datos preprocessados
load_chronos_pipeline_op()     # Carga modelo pre-entrenado (GPU detect, S3)
prepare_chronos_data_op()      # Prepara formato temporal
train_chronos_model_op()       # Routes a 3 m√©todos de training
evaluate_chronos_model_op()    # Evaluaci√≥n batch en val/test
save_chronos_model_op()        # Guarda fine-tuned (~455MB)
log_chronos_mlflow_op()        # Loggea m√©tricas a MLflow
```

---

## üí° Implementaci√≥n

### Multi-Modelo con YAML

**Caracter√≠stica clave**: Cambiar de modelo editando solo el YAML.

**Ejemplo - De XGBoost a CatBoost**:

```yaml
# config/training/my_model.yaml

# ANTES (XGBoost)
model:
  type: xgboost
  parameters:
    max_depth: 10
    learning_rate: 0.01

# DESPU√âS (CatBoost)
model:
  type: catboost
  parameters:
    depth: 8
    learning_rate: 0.03
```

**Routing interno** (`src/dagster_pipeline/ops.py`):

```python
def train_model_op(context, data, config):
    model_type = config['model']['type']
    
    if model_type == "xgboost":
        return _train_xgboost(context, X_train, y_train, config)
    elif model_type == "lightgbm":
        return _train_lightgbm(context, X_train, y_train, config)
    elif model_type == "catboost":
        return _train_catboost(context, X_train, y_train, config)
    # ...
```

### GPU Autom√°tico

**Todos los modelos** detectan GPU autom√°ticamente:

```python
import torch

device = "cuda" if torch.cuda.is_available() else "cpu"
context.log.info(f"Using device: {device}")

if device == "cuda":
    model = load_model(device_map="auto", torch_dtype=torch.bfloat16)
else:
    model = load_model(device_map="cpu", torch_dtype=torch.float32)
```

**Hardware disponible**:
- NVIDIA RTX 4070 (12GB VRAM)
- CUDA 12.1
- PyTorch 2.1.0+cu121

### MLflow Integration

**4 experimentos configurados**:
- `steel_energy_optimization` - Modelos tradicionales
- `chronos2_zeroshot` - Chronos-2 zero-shot
- `chronos2_finetuned` - Chronos-2 fine-tuned
- `chronos2_covariates` - Chronos-2 con covariables

**Qu√© se loggea**:
- ‚úÖ Parameters (learning_rate, max_depth, num_steps, etc.)
- ‚úÖ Metrics (RMSE, MAE, R¬≤, MAPE)
- ‚úÖ Tags (model_type, gpu_used, device, approach)
- ‚úÖ Modelos tradicionales completos
- ‚ö†Ô∏è **Chronos-2**: Solo path (modelo muy grande: ~455MB)

---

## üìÅ Archivos Creados

### C√≥digo

| Archivo | L√≠neas | Prop√≥sito |
|---------|--------|-----------|
| `src/dagster_pipeline/chronos_ops.py` | 461 | 7 ops para Chronos-2 |
| `src/dagster_pipeline/chronos_jobs.py` | 103 | 3 jobs de Chronos-2 |
| `src/dagster_pipeline/definitions.py` | 24 | Entry point actualizado |

### Configuraciones

| Archivo | L√≠neas | Modelo | Prellenado |
|---------|--------|--------|------------|
| `config/training/chronos2_zeroshot_config.yaml` | 59 | Zero-shot inference | ‚úÖ |
| `config/training/chronos2_finetuned_config.yaml` | 88 | Fine-tuning sin covariables | ‚úÖ |
| `config/training/chronos2_covariates_config.yaml` | 120 | Fine-tuning con 9 covariables | ‚úÖ |

### Scripts

| Archivo | L√≠neas | Plataforma |
|---------|--------|------------|
| `scripts/start-dagster.ps1` | 60 | Windows PowerShell |
| `scripts/start-dagster.sh` | 52 | Linux/macOS Bash |

### Documentaci√≥n

| Archivo | L√≠neas | Audiencia |
|---------|--------|-----------|
| `docs/guides/DAGSTER_GUIDE.md` | 850+ | Developers, MLOps Engineers (consolidada) |
| `docs/CHRONOS-QUICKSTART.md` | 400+ | ML Engineers |
| `docs/us-resolved/us-019.md` | Este archivo | Technical Leads |

**Total**: ~1,377 l√≠neas de c√≥digo + 1,250+ l√≠neas de documentaci√≥n consolidada

---

## üöÄ Uso

### Iniciar Dagster

**PowerShell**:
```powershell
.\scripts\start-dagster.ps1
# O en otro puerto
.\scripts\start-dagster.ps1 -Port 3001
```

**Bash**:
```bash
./scripts/start-dagster.sh
# O en otro puerto
./scripts/start-dagster.sh 3001
```

### Ejecutar un Job

1. Abrir UI: http://127.0.0.1:3000
2. Click en "Jobs" (sidebar)
3. Seleccionar job (ej: `chronos_finetuned_job`)
4. Click en "Launchpad"
5. **Revisar configuraci√≥n prellenada** (ya viene con valores por defecto):
   ```yaml
   config:
     config_path: "config/training/chronos2_finetuned_config.yaml"
   ```
6. **Opcional**: Editar el `config_path` si quieres usar otra configuraci√≥n
7. Click en "Launch Run"
8. Monitorear ejecuci√≥n en tiempo real

### Cambiar de Modelo

**Sin tocar c√≥digo**:

1. Editar `config/training/my_model.yaml`:
   ```yaml
   model:
     type: catboost  # Cambiar de xgboost a catboost
   ```
2. Ejecutar mismo job
3. Dagster detecta el cambio autom√°ticamente

---

## üß™ Testing

### Verificaci√≥n Manual

```powershell
# 1. Verificar Dagster funciona
.\scripts\start-dagster.ps1
# Abrir http://127.0.0.1:3000 ‚Üí Ver 4 jobs

# 2. Probar CatBoost
# En Launchpad:
ops:
  load_config_op:
    config:
      config_path: "config/training/catboost_config.yaml"
# Launch Run ‚Üí Verificar √©xito

# 3. Probar Chronos-2
# En Launchpad (chronos_zeroshot_job):
ops:
  load_chronos_config_op:
    config:
      config_path: "config/training/chronos2_zeroshot_config.yaml"
# Launch Run ‚Üí Verificar GPU detection
```

### M√©tricas de √âxito

| M√©trica | Target | Resultado |
|---------|--------|-----------|
| UI funcional sin workers | S√≠ | ‚úÖ Confirmado |
| Jobs visibles en UI | 4 | ‚úÖ 4/4 |
| Multi-modelo XGBoost/CatBoost | YAML only | ‚úÖ Verificado |
| GPU detection | Auto | ‚úÖ RTX 4070 detectado |
| MLflow logging | 100% | ‚úÖ Todos los modelos |
| Chronos-2 pipeline | 3 variantes | ‚úÖ 3/3 implementadas |

---

## üìä Resultados

### Migraci√≥n Prefect ‚Üí Dagster

| Aspecto | Prefect v3 | Dagster 1.9.0 | Mejora |
|---------|------------|---------------|--------|
| UI funcional | ‚ùå Requiere workers | ‚úÖ Sin workers | +100% |
| Visualizaci√≥n DAG | ‚ùå Errores websockets | ‚úÖ Tiempo real | +100% |
| Setup inicial | 5 comandos | 1 comando | -80% |
| Compatibilidad MLflow | ‚úÖ | ‚úÖ | Igual |
| Compatibilidad DVC | ‚úÖ | ‚úÖ | Igual |

### Multi-Modelo

**Antes (c√≥digo hardcodeado)**:
- 1 modelo por pipeline
- Cambio requiere editar c√≥digo Python
- Testing: modificar c√≥digo + tests

**Despu√©s (YAML-driven)**:
- 8 modelos con mismo pipeline
- Cambio: solo editar YAML
- Testing: cambiar config, ejecutar

### Chronos-2 Foundation Model

**Capacidades**:
- ‚úÖ Zero-shot inference (baseline r√°pido)
- ‚úÖ Fine-tuning adaptado a dominio sider√∫rgico
- ‚úÖ Multivariate forecasting (9 covariables)
- ‚úÖ GPU acceleration (RTX 4070)
- ‚úÖ Batch processing eficiente

**Thresholds**:
- Zero-shot: RMSE <55 kWh, R¬≤ >0.75
- Fine-tuned: RMSE <50 kWh, R¬≤ >0.80
- Covariates: RMSE <42 kWh, R¬≤ >0.85

---

## üéì Lecciones Aprendidas

### ‚úÖ Lo que Funcion√≥

1. **Migraci√≥n incremental**: Mantener Prefect hasta validar Dagster 100%
2. **Arquitectura multi-modelo desde inicio**: Evit√≥ refactors posteriores
3. **GPU detection autom√°tico**: Sin configuraci√≥n manual por modelo
4. **Scripts de inicio**: Reducci√≥n dr√°stica en fricci√≥n de setup
5. **Foundation models en ops separadas**: Evita contaminar pipeline tradicional

### ‚ö†Ô∏è Desaf√≠os

1. **Chronos-2 modelo muy grande**: 455MB no cabe en MLflow artifacts
   - Soluci√≥n: Solo loggear path, no el modelo
   
2. **Configuraci√≥n de covariables compleja**: 9 variables en YAML
   - Soluci√≥n: YAML con validaci√≥n expl√≠cita
   
3. **Linter de Dagster**: Falsos positivos en inyecci√≥n de dependencias
   - Soluci√≥n: Ignorar errores espec√≠ficos de context injection

4. **API de Chronos-2 cambi√≥**: Variant paths antiguos no funcionaban
   - Soluci√≥n: Usar path S3 correcto `s3://autogluon/chronos-2`
   
5. **Configuraci√≥n manual en Launchpad**: Usuarios ten√≠an que escribir YAML
   - Soluci√≥n: Implementar clase `Config` con valores por defecto

### üöÄ Best Practices Establecidas

1. **SIEMPRE usar YAML** para configuraci√≥n de modelos
2. **NUNCA hardcodear** paths o hiperpar√°metros
3. **GPU detection** debe ser autom√°tico con fallback
4. **Modelos grandes** (>100MB) NO van a MLflow artifacts
5. **Ops de foundation models** en archivos separados (`chronos_ops.py`)
6. **Scripts de inicio** para todos los servicios (Dagster, MLflow, etc.)
7. **Configuraci√≥n prellenada** en Launchpad para mejor UX
8. **Usar paths S3 oficiales** para modelos de HuggingFace/AutoGluon
9. **Documentaci√≥n consolidada** en gu√≠as √∫nicas, no fragmentadas

---

## üîó Referencias

### Documentaci√≥n

- [**DAGSTER_GUIDE.md**](../guides/DAGSTER_GUIDE.md) - Gu√≠a consolidada completa (workflows, multi-modelo, configuraci√≥n)
- [**CHRONOS-QUICKSTART.md**](../CHRONOS-QUICKSTART.md) - Gu√≠a r√°pida Chronos-2
- [**US-019-VERIFICATION-REPORT.md**](US-019-VERIFICATION-REPORT.md) - Reporte t√©cnico (si existe)

### Enlaces Externos

- [Dagster Docs](https://docs.dagster.io/)
- [Chronos-2 GitHub](https://github.com/amazon-science/chronos-forecasting)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)

### C√≥digo Relevante

- `src/dagster_pipeline/` - Todo el c√≥digo de pipeline
- `config/training/` - Configuraciones YAML de modelos
- `scripts/start-dagster.*` - Scripts de inicio

---

## üìù Pr√≥ximos Pasos

### ‚úÖ Completado

- [x] Migraci√≥n Prefect ‚Üí Dagster
- [x] Soporte multi-modelo (8 modelos)
- [x] Pipeline Chronos-2 (3 variantes)
- [x] Scripts de inicio
- [x] Documentaci√≥n consolidada
- [x] Configuraci√≥n prellenada en Launchpad
- [x] Fix de API de Chronos-2 (S3 path)
- [x] Op `load_chronos_data_op` implementado

### üîÑ Pendiente (Futuras US)

- [ ] Schedules autom√°ticos en Dagster
- [ ] Sensors para re-entrenamiento autom√°tico
- [ ] Assets para feature stores
- [ ] CI/CD pipeline con GitHub Actions
- [ ] Deployment a producci√≥n (Docker + Kubernetes)
- [ ] Monitoreo con Prometheus/Grafana
- [ ] Alertas autom√°ticas (Slack/Email)

### üí° Mejoras Propuestas

1. **Dagster Cloud**: Migrar a Dagster+ para UI hosted
2. **Hyperparameter tuning**: Integrar Optuna en pipeline
3. **A/B testing**: Comparaci√≥n autom√°tica de modelos
4. **Model registry**: Usar MLflow Model Registry
5. **Data drift detection**: Monitoreo de distribuciones

---

## üéâ Conclusi√≥n

US-019 cumpli√≥ exitosamente todos los objetivos:

1. ‚úÖ **Migraci√≥n a Dagster** sin regresiones
2. ‚úÖ **Multi-modelo** funcional (8 modelos)
3. ‚úÖ **Foundation model** integrado (Chronos-2)
4. ‚úÖ **Developer Experience** mejorado (scripts, docs, configuraci√≥n prellenada)
5. ‚úÖ **Documentaci√≥n consolidada** en gu√≠a √∫nica

La arquitectura resultante es:
- **Escalable**: Agregar nuevos modelos solo requiere YAML + routing
- **Mantenible**: C√≥digo organizado, documentado, testeado
- **Flexible**: GPU/CPU, MLflow/DVC, tradicional/foundation models
- **Productiva**: Scripts automatizan tareas repetitivas

**Estado del Proyecto**: Listo para US-020 (Deployment).

---

**Autor**: MLOps Team - Proyecto Atreides  
**Fecha Inicial**: 2025-01-16  
**√öltima Actualizaci√≥n**: 2025-11-05  
**Versi√≥n**: 1.1  
**Revisores**: Arthur (Tech Lead)

---

## üìù Changelog

### v1.1 (2025-11-05)
- ‚úÖ Agregada configuraci√≥n prellenada en Launchpad
- ‚úÖ Fix de API de Chronos-2 (usar S3 path correcto)
- ‚úÖ Implementado op `load_chronos_data_op`
- ‚úÖ Documentaci√≥n consolidada en `DAGSTER_GUIDE.md`
- ‚úÖ Actualizado README.md con referencias correctas

### v1.0 (2025-01-16)
- ‚úÖ Migraci√≥n inicial Prefect ‚Üí Dagster
- ‚úÖ Implementaci√≥n de 4 jobs (1 tradicional + 3 Chronos)
- ‚úÖ Scripts de inicio multiplataforma
- ‚úÖ Documentaci√≥n inicial
