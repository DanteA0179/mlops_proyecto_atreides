# Gu√≠a Completa de Dagster - Energy Optimization Copilot

**√öltima actualizaci√≥n**: 5 de Noviembre, 2025  
**Versi√≥n Dagster**: 1.9.0

Esta gu√≠a unificada cubre todo lo que necesitas saber sobre Dagster en el proyecto: workflows, multi-modelo, configuraci√≥n y troubleshooting.

---

## üìã Tabla de Contenidos

1. [Introducci√≥n](#-introducci√≥n)
2. [Arquitectura](#Ô∏è-arquitectura)
3. [Jobs Disponibles](#-jobs-disponibles)
4. [Inicio R√°pido](#-inicio-r√°pido)
5. [Multi-Modelo con YAML](#Ô∏è-multi-modelo-con-yaml)
6. [Configuraci√≥n del Launchpad](#-configuraci√≥n-del-launchpad)
7. [GPU Autom√°tico](#-gpu-autom√°tico)
8. [MLflow Integration](#-mlflow-integration)
9. [Modelos Soportados](#-modelos-soportados)
10. [Troubleshooting](#-troubleshooting)

---

## üéØ Introducci√≥n

Este proyecto usa **Dagster** como orquestador de pipelines de ML, reemplazando a Prefect v3 que presentaba problemas de UI y dependencias de workers.

### Ventajas de Dagster

- ‚úÖ UI funciona sin workers
- ‚úÖ Visualizaci√≥n clara del DAG
- ‚úÖ Type-safe con Python types
- ‚úÖ Compatible con MLflow, DVC, Polars
- ‚úÖ Soporte multi-modelo via YAML
- ‚úÖ Configuraci√≥n prellenada en Launchpad

---

## üèóÔ∏è Arquitectura

### Estructura de C√≥digo

```
src/dagster_pipeline/
‚îú‚îÄ‚îÄ definitions.py          # Entry point - Define all jobs
‚îú‚îÄ‚îÄ ops.py                  # Ops para modelos tradicionales (10 ops)
‚îú‚îÄ‚îÄ chronos_ops.py          # Ops para Chronos-2 (8 ops)
‚îú‚îÄ‚îÄ jobs.py                 # Jobs de modelos tradicionales
‚îú‚îÄ‚îÄ chronos_jobs.py         # Jobs de Chronos-2 (3 jobs)
‚îî‚îÄ‚îÄ working_pipeline.py     # Pipeline principal multi-modelo
```

### Conceptos Clave

| Concepto | Descripci√≥n | Equivalente Prefect |
|----------|-------------|---------------------|
| **Op** | Unidad b√°sica de computaci√≥n | Task |
| **Job** | Grafo de ejecuci√≥n de Ops | Flow |
| **Asset** | Dato materializable | Output |
| **Resource** | Dependencia externa (DB, API) | Block |
| **Config** | Configuraci√≥n de ops | Parameters |

---

## üì¶ Jobs Disponibles

### 1. `complete_training_job`

**Modelos**: XGBoost, LightGBM, CatBoost, 2 Ensembles

**Pipeline** (10 ops):
```
Load Config ‚Üí Load Data ‚Üí Validate Data ‚Üí Train Model ‚Üí Evaluate ‚Üí
Check Threshold ‚Üí Log MLflow ‚Üí Save Artifacts ‚Üí DVC Add ‚Üí Notification
```

**Caracter√≠sticas**:
- ‚úÖ Multi-modelo: Cambia modelo editando solo el YAML
- ‚úÖ GPU con fallback autom√°tico a CPU
- ‚úÖ Validaci√≥n de calidad de datos
- ‚úÖ Threshold checks (RMSE, R¬≤, MAE)
- ‚úÖ MLflow tracking completo
- ‚úÖ Versionado con DVC
- ‚úÖ Configuraci√≥n prellenada (XGBoost por defecto)

**Configuraciones disponibles**:
- `config/training/xgboost_config.yaml` (por defecto)
- `config/training/lightgbm_config.yaml`
- `config/training/catboost_config.yaml`
- `config/training/ensemble_lightgbm_config.yaml`
- `config/training/ensemble_ridge_config.yaml`

---

### 2. `chronos_zeroshot_job`

**Modelo**: Chronos-2 (amazon/chronos-t5-small) - Zero-shot

**Pipeline** (6 ops):
```
Load Config ‚Üí Load Data ‚Üí Load Pipeline ‚Üí Prepare Data ‚Üí Evaluate ‚Üí Log MLflow
```

**Caracter√≠sticas**:
- ‚úÖ **Sin entrenamiento** (usa modelo pre-entrenado)
- ‚úÖ Inference directa en datos temporales
- ‚úÖ GPU autom√°tico (RTX 4070)
- ‚úÖ Batch processing eficiente
- ‚úÖ M√©tricas solo en MLflow (modelo NO se guarda)
- ‚úÖ Configuraci√≥n prellenada

**Configuraci√≥n**:
- `config/training/chronos2_zeroshot_config.yaml` (por defecto)

**Uso**: Para baseline r√°pido sin costo de entrenamiento (~2-3 min).

---

### 3. `chronos_finetuned_job`

**Modelo**: Chronos-2 fine-tuned (sin covariables)

**Pipeline** (8 ops):
```
Load Config ‚Üí Load Data ‚Üí Load Pipeline ‚Üí Prepare Data ‚Üí Fine-tune ‚Üí
Evaluate ‚Üí Save Model ‚Üí Log MLflow
```

**Caracter√≠sticas**:
- ‚úÖ Fine-tuning de 1000 steps (configurable)
- ‚úÖ Learning rate: 1e-5
- ‚úÖ Gradient accumulation: 4
- ‚úÖ Batch size: 8
- ‚úÖ GPU requerido (‚âà455MB modelo)
- ‚úÖ Modelo guardado en `models/foundation/`
- ‚úÖ M√©tricas en MLflow
- ‚úÖ Configuraci√≥n prellenada

**Configuraci√≥n**:
- `config/training/chronos2_finetuned_config.yaml` (por defecto)

**Uso**: Para adaptar Chronos-2 a nuestro dominio (siderurgia).

---

### 4. `chronos_covariates_job`

**Modelo**: Chronos-2 fine-tuned con 9 covariables pasadas

**Pipeline** (8 ops):
```
Load Config ‚Üí Load Data ‚Üí Load Pipeline ‚Üí Prepare Data (with covariates) ‚Üí
Fine-tune ‚Üí Evaluate ‚Üí Save Model ‚Üí Log MLflow
```

**Caracter√≠sticas**:
- ‚úÖ Fine-tuning con contexto multivariado
- ‚úÖ 9 past_covariates:
  - `Lagging_Current_Reactive.Power_kVarh`
  - `Leading_Current_Reactive_Power_kVarh`
  - `CO2(tCO2)`
  - `Lagging_Current_Power_Factor`
  - `Leading_Current_Power_Factor`
  - `NSM`
  - `WeekStatus`
  - `Day_of_week`
  - `Load_Type`
- ‚úÖ Mejor rendimiento esperado (RMSE <42 kWh)
- ‚úÖ GPU requerido
- ‚úÖ Modelo guardado (~455MB)
- ‚úÖ Configuraci√≥n prellenada

**Configuraci√≥n**:
- `config/training/chronos2_covariates_config.yaml` (por defecto)

**Uso**: Para m√°ximo rendimiento aprovechando variables correlacionadas.

---

## üöÄ Inicio R√°pido

### 1. Iniciar Dagster

**PowerShell (Windows)**:
```powershell
.\scripts\start-dagster.ps1

# O especificar puerto
.\scripts\start-dagster.ps1 -Port 3001
```

**Bash (Linux/macOS)**:
```bash
./scripts/start-dagster.sh

# O especificar puerto
./scripts/start-dagster.sh 3001
```

### 2. Abrir UI

Navegar a: **http://127.0.0.1:3000**

### 3. Ejecutar un Job

1. **Click en "Jobs"** (sidebar izquierdo)
2. **Selecciona un job** (ej: `chronos_finetuned_job`)
3. **Click en "Launchpad"**
4. **Revisar configuraci√≥n prellenada** (ya viene con valores por defecto)
5. **Opcional**: Editar el `config_path` si quieres usar otra configuraci√≥n
6. **Click en "Launch Run"**

### 4. Monitorear Ejecuci√≥n

- Ver progreso en tiempo real
- Logs de cada op
- Tiempo de ejecuci√≥n
- Success/failure status
- Gr√°fico del DAG

---

## üéõÔ∏è Multi-Modelo con YAML

La arquitectura multi-modelo permite **cambiar de modelo SIN tocar c√≥digo**, solo editando el YAML.

### Ejemplo: Cambiar de XGBoost a CatBoost

**Antes** (XGBoost):
```yaml
# config/training/my_model.yaml
model:
  type: xgboost
  parameters:
    max_depth: 10
    learning_rate: 0.01
```

**Despu√©s** (CatBoost):
```yaml
# config/training/my_model.yaml
model:
  type: catboost
  parameters:
    depth: 8
    learning_rate: 0.03
    iterations: 500
```

**Ejecuci√≥n**: La misma (Dagster detecta el cambio autom√°ticamente).

### Routing Interno

El routing se hace en `src/dagster_pipeline/ops.py` ‚Üí `train_model_op()`:

```python
def train_model_op(context: OpExecutionContext, data: tuple, cfg: dict) -> Any:
    model_type = cfg['model']['type']
    
    if model_type == "xgboost":
        model = _train_xgboost(context, X_train, y_train, cfg)
    elif model_type == "lightgbm":
        model = _train_lightgbm(context, X_train, y_train, cfg)
    elif model_type == "catboost":
        model = _train_catboost(context, X_train, y_train, cfg)
    elif model_type in ["ensemble_lightgbm", "ensemble_ridge"]:
        model = _train_ensemble(context, X_train, y_train, cfg, data)
    # ...
```

Para Chronos-2, el routing est√° en `chronos_ops.py` ‚Üí `train_chronos_model_op()`:

```python
def train_chronos_model_op(context, pipeline, prepared_data, cfg):
    model_type = cfg['model']['type']
    
    if model_type == "chronos2_zeroshot":
        return pipeline  # No training
    elif model_type == "chronos2_finetuned":
        return _finetune_chronos_simple(...)
    elif model_type == "chronos2_covariates":
        return _finetune_chronos_covariates(...)
```

---

## üîß Configuraci√≥n del Launchpad

### Configuraci√≥n Prellenada (Nuevo!)

Todos los jobs ahora vienen con **configuraci√≥n prellenada** en el Launchpad. Ya no necesitas escribir el YAML manualmente.

#### Job: `complete_training_job`

**Configuraci√≥n por defecto** (XGBoost):
```yaml
config:
  config_path: "config/training/xgboost_config.yaml"
```

**Para cambiar a otro modelo**, simplemente edita el path:
```yaml
config:
  config_path: "config/training/lightgbm_config.yaml"
```

#### Job: `chronos_zeroshot_job`

**Configuraci√≥n por defecto**:
```yaml
config:
  config_path: "config/training/chronos2_zeroshot_config.yaml"
```

#### Job: `chronos_finetuned_job`

**Configuraci√≥n por defecto**:
```yaml
config:
  config_path: "config/training/chronos2_finetuned_config.yaml"
```

#### Job: `chronos_covariates_job`

**Configuraci√≥n por defecto**:
```yaml
config:
  config_path: "config/training/chronos2_covariates_config.yaml"
```

### Personalizar Configuraci√≥n

Si quieres usar una configuraci√≥n personalizada:

1. Crea tu archivo YAML en `config/training/`
2. En el Launchpad, edita el `config_path`:
```yaml
config:
  config_path: "config/training/mi_config_personalizado.yaml"
```

---

## üéÆ GPU Autom√°tico

Todos los modelos (XGBoost, LightGBM, CatBoost, Chronos-2) tienen **detecci√≥n autom√°tica de GPU** con fallback a CPU.

### Implementaci√≥n

```python
import torch

# Detect device
device = "cuda" if torch.cuda.is_available() else "cpu"
context.log.info(f"Using device: {device}")

# Configure model
if device == "cuda":
    # GPU config
    model = load_model(device_map="auto", torch_dtype=torch.bfloat16)
else:
    # CPU config
    model = load_model(device_map="cpu", torch_dtype=torch.float32)
```

### GPU Disponible

- **Hardware**: NVIDIA RTX 4070
- **VRAM**: 12GB
- **CUDA**: 12.1
- **PyTorch**: 2.1.0+cu121

### Logs

Con GPU:
```
INFO - Detecting GPU...
INFO - GPU detected: NVIDIA GeForce RTX 4070
INFO - Using device: cuda
INFO - Loading model with bfloat16 precision
```

Sin GPU:
```
INFO - Detecting GPU...
INFO - No GPU detected, using CPU
INFO - Using device: cpu
INFO - Loading model with float32 precision
```

---

## üìä MLflow Integration

Todos los jobs loggean autom√°ticamente a MLflow.

### Configuraci√≥n

**MLflow Server**: http://localhost:5000

**Experimentos**:
- `steel_energy_optimization` - Modelos tradicionales
- `chronos2_zeroshot` - Chronos-2 zero-shot
- `chronos2_finetuned` - Chronos-2 fine-tuned
- `chronos2_covariates` - Chronos-2 con covariables

### Qu√© se Loggea

#### Modelos Tradicionales (XGBoost, etc.)
- ‚úÖ Parameters (learning_rate, max_depth, etc.)
- ‚úÖ Metrics (RMSE, MAE, R¬≤, MAPE)
- ‚úÖ Tags (model_type, gpu_used, framework)
- ‚úÖ **Modelo completo** (via `mlflow.sklearn.log_model`)
- ‚úÖ Artifacts (model.pkl, metrics.json)

#### Chronos-2
- ‚úÖ Parameters (context_length, num_steps, lr, etc.)
- ‚úÖ Metrics (RMSE, MAE, R¬≤, MAPE)
- ‚úÖ Tags (model_type, approach, device)
- ‚úÖ **Path al modelo** (no el modelo completo)
- ‚ö†Ô∏è **Modelo NO loggeado** (demasiado grande: ~455MB)

**Raz√≥n**: MLflow tiene l√≠mite de 100MB por artifact. Chronos-2 fine-tuned pesa ~455MB.

### Ver Resultados

1. **Iniciar MLflow UI**:
   ```bash
   poetry run mlflow ui
   ```

2. **Abrir**: http://localhost:5000

3. **Comparar runs**:
   - Click en experimento
   - Selecciona m√∫ltiples runs
   - Click en "Compare"
   - Ver gr√°ficas de m√©tricas

---

## üéØ Modelos Soportados

### ‚úÖ Modelos Tradicionales (Solo cambiar YAML)

| Modelo | Config File | Tiempo | GPU |
|--------|-------------|--------|-----|
| **XGBoost** | `xgboost_config.yaml` | ~1 min | ‚úÖ |
| **LightGBM** | `lightgbm_config.yaml` | ~1 min | ‚úÖ |
| **CatBoost** | `catboost_config.yaml` | ~1 min | ‚úÖ |
| **Ensemble LightGBM** | `ensemble_lightgbm_config.yaml` | ~3-5 min | ‚úÖ |
| **Ensemble Ridge** | `ensemble_ridge_config.yaml` | ~3-5 min | ‚úÖ |

### ‚úÖ Foundation Models (Chronos-2)

| Modelo | Config File | Tiempo | GPU |
|--------|-------------|--------|-----|
| **Zero-Shot** | `chronos2_zeroshot_config.yaml` | ~30s | ‚úÖ |
| **Fine-Tuned** | `chronos2_finetuned_config.yaml` | ~2-4 min (10 steps) | ‚úÖ Requerido |
| **Covariates** | `chronos2_covariates_config.yaml` | ~4-8 min (10 steps) | ‚úÖ Requerido |

### Cu√°ndo usar cada modelo

| Modelo | Mejor Para | Ventajas | Desventajas |
|--------|-----------|----------|-------------|
| **XGBoost** | Baseline r√°pido | R√°pido, robusto, GPU support | Puede overfittear |
| **LightGBM** | Datasets grandes | Muy r√°pido, eficiente memoria | Sensible a hiperpar√°metros |
| **CatBoost** | Features categ√≥ricas | Maneja categor√≠as nativamente | M√°s lento |
| **Ensemble** | M√°xima precisi√≥n | Mejor performance | Lento, complejo |
| **Chronos Zero-Shot** | Baseline temporal r√°pido | Sin entrenamiento | Performance limitado |
| **Chronos Fine-Tuned** | Forecasting adaptado | Captura patrones temporales | Requiere GPU, lento |
| **Chronos Covariates** | M√°xima precisi√≥n temporal | Usa contexto multivariado | M√°s lento, m√°s complejo |

### Recomendaci√≥n de Workflow

```bash
# 1. Entrenar modelos tradicionales
# En Dagster UI, ejecutar secuencialmente:
# - xgboost_config.yaml
# - lightgbm_config.yaml  
# - catboost_config.yaml

# 2. Comparar en MLflow
# http://localhost:5000
# Ver cu√°l tiene mejor RMSE/R¬≤

# 3. Entrenar ensemble con los 3 mejores
# - ensemble_lightgbm_config.yaml

# 4. Probar Chronos-2
# - chronos2_zeroshot_config.yaml (baseline)
# - chronos2_finetuned_config.yaml (adaptado)
# - chronos2_covariates_config.yaml (m√°xima precisi√≥n)

# 5. Comparar todos en MLflow
# Elegir el mejor modelo para producci√≥n
```

---

## üîß Troubleshooting

### Problema: "Port 3000 already in use"

**Soluci√≥n**: Usa otro puerto
```powershell
.\scripts\start-dagster.ps1 -Port 3001
```

---

### Problema: "Module dagster not found"

**Causa**: Entorno virtual no activado

**Soluci√≥n**:
```bash
poetry install
poetry shell
```

---

### Problema: "CUDA out of memory"

**Causa**: Batch size muy grande para GPU

**Soluci√≥n**: Reducir batch_size en config
```yaml
chronos:
  batch_size: 4  # Era 8
```

---

### Problema: "Config file not found"

**Causa**: Path relativo incorrecto en Launchpad

**Soluci√≥n**: Usar path relativo desde ra√≠z del proyecto
```yaml
config:
  config_path: "config/training/chronos2_finetuned_config.yaml"  # ‚úÖ Correcto
  # NO: "C:/Users/..." (path absoluto)
```

---

### Problema: "Chronos model too large for MLflow"

**Esperado**: Los modelos Chronos-2 fine-tuned NO se loggean a MLflow.

**Soluci√≥n**: El path se loggea como par√°metro. Para cargar modelo:
```python
import mlflow

run = mlflow.get_run(run_id)
model_path = run.data.params['model_path']

from chronos import Chronos2Pipeline
pipeline = Chronos2Pipeline.from_pretrained(model_path)
```

---

### Problema: "No jobs visible in UI"

**Causa**: Error al cargar definitions

**Soluci√≥n**: Verificar logs del servidor
```bash
# Ver logs en la terminal donde ejecutaste start-dagster
# Buscar errores de import o sintaxis
```

---

### Problema: "Job execution failed"

**Pasos de debugging**:

1. **Ver logs del op que fall√≥** en la UI
2. **Verificar configuraci√≥n** del YAML
3. **Verificar datos** existen en `data/processed/`
4. **Verificar GPU** si es Chronos: `nvidia-smi`
5. **Ejecutar script directo** para debugging:
   ```bash
   poetry run python src/models/train_xgboost.py
   ```

---

## üìö Referencias

- [Dagster Docs](https://docs.dagster.io/)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)
- [Chronos-2 GitHub](https://github.com/amazon-science/chronos-forecasting)
- [XGBoost GPU](https://xgboost.readthedocs.io/en/stable/gpu/index.html)
- [US-019 Documentation](../us-resolved/us-019.md) - Migraci√≥n a Dagster

---

## üéì Best Practices

1. **Usa la UI** para desarrollo y debugging
2. **Usa CLI** para producci√≥n y automatizaci√≥n
3. **Valida configs** antes de ejecutar (especialmente paths)
4. **Monitorea GPU** con `nvidia-smi` durante fine-tuning
5. **Compara runs** en MLflow antes de elegir modelo
6. **Versiona modelos** grandes con DVC (XGBoost, CatBoost)
7. **NO versiones Chronos-2** con DVC (demasiado grande)
8. **Usa configuraci√≥n prellenada** - ya viene lista para usar
9. **Empieza con modelos r√°pidos** (XGBoost, Zero-Shot) antes de entrenar modelos lentos

---

## ‚úÖ Resumen

### Para modelos tradicionales (XGBoost, LightGBM, CatBoost, Ensemble):
- ‚úÖ **Solo cambias el YAML** en el Launchpad
- ‚úÖ **Configuraci√≥n prellenada** - lista para usar
- ‚úÖ **El c√≥digo actual ya funciona**
- ‚úÖ **GPU fallback autom√°tico**
- ‚úÖ **Mismo pipeline de 10 ops**

### Para Chronos-2:
- ‚úÖ **Pipeline separado** (6-8 ops)
- ‚úÖ **Configuraci√≥n prellenada** - lista para usar
- ‚úÖ **3 variantes** (zero-shot, fine-tuned, covariates)
- ‚úÖ **GPU autom√°tico** con fallback
- ‚úÖ **MLflow integration** completa

**Conclusi√≥n**: Puedes entrenar **8 modelos diferentes** (5 tradicionales + 3 Chronos) solo cambiando el YAML en el Launchpad. Todo viene prellenado y listo para usar.

---

**Autor**: MLOps Team - Proyecto Atreides  
**Fecha**: 5 de Noviembre, 2025  
**Versi√≥n**: 2.0 (Consolidada)
